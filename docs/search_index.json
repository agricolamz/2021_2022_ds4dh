[["index.html", "Наука о данных в R для программы Цифровых гуманитарных исследований 1 О курсе", " Наука о данных в R для программы Цифровых гуманитарных исследований Г. А. Мороз, И. С. Поздняков 1 О курсе Материалы для курса Наука о данных для магистерской программы Цифровых гуманитарные исследования НИУ ВШЭ. запись 17.01.2022 "],["viz_1.html", "2 Визуализация данных 2.1 Зачем визуализировать данные? 2.2 Основы ggplot2 2.3 Столбчатые диаграммы (barplots) 2.4 Факторы 2.5 Дотплот 2.6 Гистограммы 2.7 Функции плотности 2.8 Точки, джиттер (jitter), вайолинплот (violinplot), ящики с усами (boxplot), 2.9 Фасетизация 2.10 Визуализация комбинаций признаков", " 2 Визуализация данных library(&quot;tidyverse&quot;) 2.1 Зачем визуализировать данные? 2.1.1 Квартет Анскомба В работе Anscombe, F. J. (1973). “Graphs in Statistical Analysis” представлен следующий датасет: quartet &lt;- read_csv(&quot;https://raw.githubusercontent.com/agricolamz/2020-2021-ds4dh/master/data/anscombe.csv&quot;) quartet quartet %&gt;% group_by(dataset) %&gt;% summarise(mean_X = mean(x), mean_Y = mean(y), sd_X = sd(x), sd_Y = sd(y), cor = cor(x, y), n_obs = n()) %&gt;% select(-dataset) %&gt;% round(2) 2.1.2 Датазаурус В работе Matejka and Fitzmaurice (2017) “Same Stats, Different Graphs” были представлены следующие датасеты: datasaurus &lt;- read_csv(&quot;https://raw.githubusercontent.com/agricolamz/2020-2021-ds4dh/master/data/datasaurus.csv&quot;) datasaurus datasaurus %&gt;% group_by(dataset) %&gt;% summarise(mean_X = mean(x), mean_Y = mean(y), sd_X = sd(x), sd_Y = sd(y), cor = cor(x, y), n_obs = n()) %&gt;% select(-dataset) %&gt;% round(1) 2.2 Основы ggplot2 Пакет ggplot2 – современный стандарт для создания графиков в R. Для этого пакета пишут массу расширений. В сжатом виде информация про ggplot2 содержиться здесь. 2.2.1 Диаграмма рассеяния (Scaterplot) ggplot2 ggplot(data = diamonds, aes(carat, price)) + geom_point() dplyr, ggplot2 diamonds %&gt;% ggplot(aes(carat, price))+ geom_point() 2.2.2 Слои diamonds %&gt;% ggplot(aes(carat, price))+ geom_point()+ geom_smooth() ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; diamonds %&gt;% ggplot(aes(carat, price))+ geom_smooth()+ geom_point() ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; 2.2.3 aes() diamonds %&gt;% ggplot(aes(carat, price, color = cut))+ geom_point() diamonds %&gt;% ggplot(aes(carat, price))+ geom_point(color = &quot;green&quot;) diamonds %&gt;% ggplot(aes(carat, price))+ geom_point(aes(color = cut)) diamonds %&gt;% ggplot(aes(carat, price, shape = cut))+ geom_point() diamonds %&gt;% ggplot(aes(carat, price, label = color))+ geom_text() diamonds %&gt;% slice(1:100) %&gt;% ggplot(aes(carat, price, label = color))+ geom_label() Иногда аннотации налезают друг на друга: library(ggrepel) diamonds %&gt;% slice(1:100) %&gt;% ggplot(aes(carat, price, label = color))+ geom_text_repel() diamonds %&gt;% slice(1:100) %&gt;% ggplot(aes(carat, price, label = color))+ geom_text_repel()+ geom_point() diamonds %&gt;% slice(1:100) %&gt;% ggplot(aes(carat, price, label = color, fill = cut))+ # fill отвечает за закрашивание geom_label_repel(alpha = 0.5)+ # alpha отвечает за прозрачность geom_point() 2.2.4 Оформление diamonds %&gt;% ggplot(aes(carat, price, color = cut))+ geom_point() + labs(x = &quot;вес (в каратах)&quot;, y = &quot;цена (в долларах)&quot;, title = &quot;Связь цены и веса бриллиантов&quot;, subtitle = &quot;Данные взяты из датасеты diamonds&quot;, caption = &quot;график сделан при помощи пакета ggplot2&quot;)+ theme(legend.position = &quot;bottom&quot;) # у функции theme() огромный функционал 2.2.5 Логарифмические шкалы Рассмотрим словарь [Ляшевской, Шарова 2011] freqdict &lt;- read_tsv(&quot;https://github.com/agricolamz/2020-2021-ds4dh/raw/master/data/freq_dict_2011.csv&quot;) ## Rows: 52138 Columns: 3 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;\\t&quot; ## chr (2): lemma, pos ## dbl (1): freq_ipm ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. freqdict %&gt;% arrange(desc(freq_ipm)) %&gt;% mutate(id = 1:n()) %&gt;% slice(1:150) %&gt;% ggplot(aes(id, freq_ipm))+ geom_point() freqdict %&gt;% arrange(desc(freq_ipm)) %&gt;% mutate(id = 1:n()) %&gt;% slice(1:150) %&gt;% ggplot(aes(id, freq_ipm, label = lemma))+ geom_point()+ geom_text_repel()+ scale_y_log10() 2.2.6 annotate() Функция annotate добавляет geom к графику. diamonds %&gt;% ggplot(aes(carat, price, color = cut))+ geom_point()+ annotate(geom = &quot;rect&quot;, xmin = 4.8, xmax = 5.2, ymin = 17500, ymax = 18500, fill = &quot;red&quot;, alpha = 0.2) + annotate(geom = &quot;text&quot;, x = 4.7, y = 16600, label = &quot;помогите...\\n я в розовом\\nквадратике&quot;) Скачайте вот этот датасет и постройте диаграмму рассеяния. 2.3 Столбчатые диаграммы (barplots) Одна и та же информация может быть представлена в агрегированном и не агрегированном варианте: misspelling &lt;- read_csv(&quot;https://raw.githubusercontent.com/agricolamz/2020-2021-ds4dh/master/data/misspelling_dataset.csv&quot;) ## Rows: 15477 Columns: 3 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (2): correct, spelling ## dbl (1): count ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. misspelling переменные spelling аггрегирована: для каждого значения представлено значение в столбце count, которое обозначает количество каждого из написаний переменные correct неаггрегированы: в этом столбце она повторяется, для того, чтобы сделать вывод, нужно отдельно посчитать количество вариантов Для аггрегированных данных используется geom_col() misspelling %&gt;% slice(1:20) %&gt;% ggplot(aes(spelling, count))+ geom_col() Перевернем оси: misspelling %&gt;% slice(1:20) %&gt;% ggplot(aes(spelling, count))+ geom_col()+ coord_flip() Для неаггрегированных данных используется geom_bar() misspelling %&gt;% ggplot(aes(correct))+ geom_bar() Перевернем оси: misspelling %&gt;% ggplot(aes(correct))+ geom_bar()+ coord_flip() Неаггрегированный вариант можно перевести в аггрегированный: diamonds %&gt;% count(cut) Аггрегированный вариант можно перевести в неаггрегированный: diamonds %&gt;% count(cut) %&gt;% uncount(n) 2.4 Факторы Как можно заметить по предыдущему разделу, переменные на графике упорядочены по алфавиту. Чтобы это исправить нужно обсудить факторы: my_factor &lt;- factor(misspelling$correct) head(my_factor) ## [1] deschanel deschanel deschanel deschanel deschanel deschanel ## 15 Levels: deschanel galifianakis johansson kaepernick labeouf ... shyamalan levels(my_factor) ## [1] &quot;deschanel&quot; &quot;galifianakis&quot; &quot;johansson&quot; &quot;kaepernick&quot; &quot;labeouf&quot; ## [6] &quot;macaulay&quot; &quot;mcconaughey&quot; &quot;mcgwire&quot; &quot;mclachlan&quot; &quot;minaj&quot; ## [11] &quot;morissette&quot; &quot;palahniuk&quot; &quot;picabo&quot; &quot;poehler&quot; &quot;shyamalan&quot; levels(my_factor) &lt;- rev(levels(my_factor)) head(my_factor) ## [1] shyamalan shyamalan shyamalan shyamalan shyamalan shyamalan ## 15 Levels: shyamalan poehler picabo palahniuk morissette minaj ... deschanel misspelling %&gt;% mutate(correct = factor(correct, levels = c(&quot;deschanel&quot;, &quot;galifianakis&quot;, &quot;johansson&quot;, &quot;kaepernick&quot;, &quot;labeouf&quot;, &quot;macaulay&quot;, &quot;mcgwire&quot;, &quot;mclachlan&quot;, &quot;minaj&quot;, &quot;morissette&quot;, &quot;palahniuk&quot;, &quot;picabo&quot;, &quot;poehler&quot;, &quot;shyamalan&quot;, &quot;mcconaughey&quot;))) %&gt;% ggplot(aes(correct))+ geom_bar()+ coord_flip() Для работы с факторами удобно использовать пакет forcats (входит в tidyverse, вот ссылка на cheatsheet). Иногда полезной бывает функция fct_reorder(): misspelling %&gt;% count(correct) misspelling %&gt;% count(correct) %&gt;% ggplot(aes(fct_reorder(correct, n), n))+ geom_col()+ coord_flip() Кроме того, в функцию fct_reorder() можно добавит функцию, которая будет считаться на векторе, по которому группируют: diamonds %&gt;% mutate(cut = fct_reorder(cut, price, mean)) %&gt;% ggplot(aes(cut)) + geom_bar() В этом примере переменная cut упорядочена по средней mean цене price. Естественно, вместо mean можно использовать другие функции (median, min, max или даже собственные функции). Можно совмещать разные geom_...: misspelling %&gt;% count(correct) %&gt;% ggplot(aes(fct_reorder(correct, n), n, label = n))+ geom_col()+ geom_text(nudge_y = 150)+ coord_flip() На Pudding вышла статья про английские пабы. Здесь лежит немного обработанный датасет, которые они использовали. Визуализируйте 30 самых частотоных названий пабов в Великобритании. 📋 список подсказок ➡ На новостном портале meduza.io недавно вышла новость о применения закона “о неуважении к власти в интернете”. Постройте графики из этой новости. При построении графиков я использовал цвет “tan3”. 📋 список подсказок ➡ 2.5 Дотплот Иногда для случаев, когда мы исследуем числовую переменную подходит простой график, который отображает распределение наших наблюдений на одной соответствующей числовой шкале. mtcars %&gt;% ggplot(aes(mpg)) + geom_dotplot(method = &quot;histodot&quot;) ## Bin width defaults to 1/30 of the range of the data. Pick better value with `binwidth`. По оси x отложена наша переменная, каждая точка – одно наблюдение, а отложенное по оси y стоит игнорировать – оно появляется из-за ограничений пакета ggplot2. Возможно чуть понятнее будет, если добавить geom_rug(), который непосредственно отображает каждое наблюдение. mtcars %&gt;% ggplot(aes(mpg)) + geom_rug()+ geom_dotplot(method = &quot;histodot&quot;) ## Bin width defaults to 1/30 of the range of the data. Pick better value with `binwidth`. Больший смысл имеет раскрашенный вариант: mtcars %&gt;% mutate(cyl = factor(cyl)) %&gt;% ggplot(aes(mpg, fill = cyl)) + geom_rug()+ geom_dotplot(method = &quot;histodot&quot;)+ scale_y_continuous(NULL, breaks = NULL) # чтобы убрать ось y ## Bin width defaults to 1/30 of the range of the data. Pick better value with `binwidth`. Как видно, на графике, одна синяя точка попала под одну зеленую: значит они имеют общее наблюдение. 2.6 Гистограммы Если наблюдений слишком много, дотплот не имеем много смысла: diamonds %&gt;% ggplot(aes(price)) + geom_dotplot(method = &quot;histodot&quot;)+ scale_y_continuous(NULL, breaks = NULL) # чтобы убрать ось y ## Bin width defaults to 1/30 of the range of the data. Pick better value with `binwidth`. diamonds %&gt;% ggplot(aes(price)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Обсудим на предыдущем примере mtcars %&gt;% ggplot(aes(mpg))+ geom_rug()+ geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. По оси x отложена наша переменная, а высота столбца говорит, сколько наблюдений имеют такое же наблюдение. Однако многое зависит от того, что мы считаем одинаковым значением: mtcars %&gt;% ggplot(aes(mpg)) + geom_rug()+ geom_histogram(bins = 100) mtcars %&gt;% ggplot(aes(mpg)) + geom_rug()+ geom_histogram(bins = 5) Существует три алгоритма встроенные в R, которые можно использовать и снимать с себя ответственность: [Sturgers 1926] nclass.Sturges(mtcars$mpg) [Scott 1979] nclass.scott(mtcars$mpg) [Freedman, Diaconis 1981] nclass.FD(mtcars$mpg) mtcars %&gt;% ggplot(aes(mpg)) + geom_histogram(bins = nclass.FD(mtcars$mpg)) Какой из методов использовался при создании следующего графика на основе встроенного датасета iris? В этом типе графика точно так же можно раскрашивать на основании другой переменной: iris %&gt;% ggplot(aes(Petal.Length, fill = Species)) + geom_rug()+ geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 2.7 Функции плотности Кроме того, существует способ использовать не такой рубленный график, а его сглаженную вариант, ыйторый строиться при помои функции плотядерной оценки ности. Важное свойство, которое стоит понимать про функцию плотности — что кривая, получаемая ядерной оценкой плотности, не зависит от величины коробки гистделения (хотя есть аргумент, который от adjustвечает за степень “близости” функции плотности к гистограмме). iris %&gt;% ggplot(aes(Petal.Length)) + geom_rug()+ geom_density() Таким образом мы можем сравнивать распределения: iris %&gt;% ggplot(aes(Petal.Length, fill = Species)) + geom_rug()+ geom_density() Часто имеет смысл настроить прозрачность: iris %&gt;% ggplot(aes(Petal.Length, fill = Species)) + geom_rug()+ geom_density(alpha = 0.6) # значение прозрачности изменяется от 0 до 1 Кроме того, иногда удобно разделять группы на разные уровни: # install.packages(ggridges) library(ggridges) iris %&gt;% ggplot(aes(Petal.Length, Species, fill = Species)) + geom_density_ridges(alpha = 0.6) # значение прозрачности изменяется от 0 до 1 ## Picking joint bandwidth of 0.155 В длинный список “2015 Kantar Information is Beautiful Awards” попала визуализация Perceptions of Probability, сделанная пользователем zonination в ggplot2. Попробуйте воспроизвести ее с этими данными. 📋 список подсказок ➡ 2.8 Точки, джиттер (jitter), вайолинплот (violinplot), ящики с усами (boxplot), Вот другие способы показать распределение числовой переменной: iris %&gt;% ggplot(aes(Species, Petal.Length))+ geom_point() iris %&gt;% ggplot(aes(Species, Petal.Length))+ geom_jitter() iris %&gt;% ggplot(aes(Species, Petal.Length))+ geom_jitter(width = 0.3) library(&quot;ggbeeswarm&quot;) iris %&gt;% ggplot(aes(Species, Petal.Length))+ geom_quasirandom() diamonds %&gt;% ggplot(aes(cut, price))+ geom_violin() diamonds %&gt;% ggplot(aes(cut, price))+ geom_boxplot() 2.9 Фасетизация Достаточно мощным инструментом анализа данных является фасетизация, которая позволяет разбивать графики на основе какой-то переменной. diamonds %&gt;% ggplot(aes(carat, price))+ geom_point(size = 0.3)+ facet_wrap(~cut) При этом иногда так бывает, что наличие какой-то одного значение в одном из фасетов, заставляет иметь одну и ту же шкалу для всех остальных. Это можно изменить при помощи аргумента scales: diamonds %&gt;% ggplot(aes(carat, price))+ geom_point(size = 0.3)+ facet_wrap(~cut, scales = &quot;free&quot;) Кроме того, можно добавлять дополнительные аргументы: diamonds %&gt;% ggplot(aes(carat, price))+ geom_point(size = 0.3)+ facet_wrap(~cut+color) Кроме того, можно создавать сетки переменных используя geom_grid(), они facet_grid()ньше места, чем facet_wrap(): diamonds %&gt;% ggplot(aes(carat, price))+ geom_point(size = 0.3)+ facet_grid(cut~color, scales = &quot;free&quot;) Кроме того facet_grid() позволяет делать обощающие поля, где представлены все данные по какой-то строчке или столбцу: diamonds %&gt;% ggplot(aes(carat, price))+ geom_point(size = 0.3)+ facet_grid(cut~color, scales = &quot;free&quot;, margins = TRUE) 2.10 Визуализация комбинаций признаков 2.10.1 Потоковая Диаграмма (Sankey diagram) Один из способов визуализации отношений между признаками называется потоковая диаграмма. library(&quot;ggforce&quot;) zhadina &lt;- read_csv(&quot;https://raw.githubusercontent.com/agricolamz/2020-2021-ds4dh/master/data/zhadina.csv&quot;) ## Rows: 26 Columns: 5 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (4): word_1, word_2, word_3, type ## dbl (1): n ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. zhadina %&gt;% gather_set_data(1:3) %&gt;% ggplot(aes(x, id = id, split = y, value = n))+ geom_parallel_sets(aes(fill = type), alpha = 0.6, axis.width = 0.5) + geom_parallel_sets_axes(axis.width = 0.5, color = &quot;lightgrey&quot;, fill = &quot;white&quot;) + geom_parallel_sets_labels(angle = 0) + theme_no_axes()+ theme(legend.position = &quot;bottom&quot;) А как поменять порядок? Снова факторы. zhadina %&gt;% gather_set_data(1:3) %&gt;% mutate(y = fct_reorder(y, n, mean)) %&gt;% ggplot(aes(x, id = id, split = y, value = n))+ geom_parallel_sets(aes(fill = type), alpha = 0.6, axis.width = 0.5) + geom_parallel_sets_axes(axis.width = 0.5, color = &quot;lightgrey&quot;, fill = &quot;white&quot;) + geom_parallel_sets_labels(angle = 0) + theme_no_axes()+ theme(legend.position = &quot;bottom&quot;) Можно донастроить, задав собственный порядок в аргументе levels функции factor(). 2.10.2 UpSet Plot Если диаграмма Sankey визуализирует попарные отношения между переменными, то график UpSet потенциально может визуализировать все возможные комбинации и является хорошей альтернативой диаграмме Вена, с большим количеством переменных (см. эту статью Лауры Эллис). library(UpSetR) movies &lt;- read.csv( system.file(&quot;extdata&quot;, &quot;movies.csv&quot;, package = &quot;UpSetR&quot;), header=TRUE, sep=&quot;;&quot; ) str(movies) ## &#39;data.frame&#39;: 3883 obs. of 21 variables: ## $ Name : chr &quot;Toy Story (1995)&quot; &quot;Jumanji (1995)&quot; &quot;Grumpier Old Men (1995)&quot; &quot;Waiting to Exhale (1995)&quot; ... ## $ ReleaseDate: int 1995 1995 1995 1995 1995 1995 1995 1995 1995 1995 ... ## $ Action : int 0 0 0 0 0 1 0 0 1 1 ... ## $ Adventure : int 0 1 0 0 0 0 0 1 0 1 ... ## $ Children : int 1 1 0 0 0 0 0 1 0 0 ... ## $ Comedy : int 1 0 1 1 1 0 1 0 0 0 ... ## $ Crime : int 0 0 0 0 0 1 0 0 0 0 ... ## $ Documentary: int 0 0 0 0 0 0 0 0 0 0 ... ## $ Drama : int 0 0 0 1 0 0 0 0 0 0 ... ## $ Fantasy : int 0 1 0 0 0 0 0 0 0 0 ... ## $ Noir : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Horror : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Musical : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Mystery : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Romance : int 0 0 1 0 0 0 1 0 0 0 ... ## $ SciFi : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Thriller : int 0 0 0 0 0 1 0 0 0 1 ... ## $ War : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Western : int 0 0 0 0 0 0 0 0 0 0 ... ## $ AvgRating : num 4.15 3.2 3.02 2.73 3.01 3.88 3.41 3.01 2.66 3.54 ... ## $ Watches : int 2077 701 478 170 296 940 458 68 102 888 ... upset(movies[,3:19], nsets = 16, order.by = &quot;freq&quot;) "],["strings.html", "3 Работа со строками 3.1 Работа со строками в R 3.2 Как получить строку? 3.3 Соединение и разделение строк 3.4 Количество символов 3.5 Сортировка 3.6 Поиск подстроки 3.7 Изменение строк 3.8 Регулярные выражения 3.9 Определение языка 3.10 Расстояния между строками 3.11 Дополнительные задания:", " 3 Работа со строками 3.1 Работа со строками в R Для работы со строками можно использовать: базовый R пакет stringr (часть tidyverse) пакет stringi – отдельный пакет, так что не забудьте его установить: install.packages(&quot;stringi&quot;) library(tidyverse) library(stringi) Мы будем пользоваться в основном пакетами stingr и stringi, так как они в большинстве случаях удобнее. К счастью функции этих пакетов легко отличить от остальных: функции пакет stringr всегда начинаются с str_, а функции пакета stringi — c stri_. Существует cheat sheet по stringr. 3.2 Как получить строку? следите за кавычками &quot;the quick brown fox jumps over the lazy dog&quot; ## [1] &quot;the quick brown fox jumps over the lazy dog&quot; &#39;the quick brown fox jumps over the lazy dog&#39; ## [1] &quot;the quick brown fox jumps over the lazy dog&quot; &quot;the quick &#39;brown&#39; fox jumps over the lazy dog&quot; ## [1] &quot;the quick &#39;brown&#39; fox jumps over the lazy dog&quot; &#39;the quick &quot;brown&quot; fox jumps over the lazy dog&#39; ## [1] &quot;the quick \\&quot;brown\\&quot; fox jumps over the lazy dog&quot; пустая строка &quot;&quot; ## [1] &quot;&quot; &#39;&#39; ## [1] &quot;&quot; character(3) ## [1] &quot;&quot; &quot;&quot; &quot;&quot; преобразование typeof(4:7) ## [1] &quot;integer&quot; as.character(4:7) ## [1] &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; встроенные векторы letters ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; &quot;j&quot; &quot;k&quot; &quot;l&quot; &quot;m&quot; &quot;n&quot; &quot;o&quot; &quot;p&quot; &quot;q&quot; &quot;r&quot; &quot;s&quot; ## [20] &quot;t&quot; &quot;u&quot; &quot;v&quot; &quot;w&quot; &quot;x&quot; &quot;y&quot; &quot;z&quot; LETTERS ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; &quot;G&quot; &quot;H&quot; &quot;I&quot; &quot;J&quot; &quot;K&quot; &quot;L&quot; &quot;M&quot; &quot;N&quot; &quot;O&quot; &quot;P&quot; &quot;Q&quot; &quot;R&quot; &quot;S&quot; ## [20] &quot;T&quot; &quot;U&quot; &quot;V&quot; &quot;W&quot; &quot;X&quot; &quot;Y&quot; &quot;Z&quot; month.name ## [1] &quot;January&quot; &quot;February&quot; &quot;March&quot; &quot;April&quot; &quot;May&quot; &quot;June&quot; ## [7] &quot;July&quot; &quot;August&quot; &quot;September&quot; &quot;October&quot; &quot;November&quot; &quot;December&quot; Создание рандомных строк set.seed(42) stri_rand_strings(n = 10, length = 5:14) ## [1] &quot;uwHpd&quot; &quot;Wj8ehS&quot; &quot;ivFSwy7&quot; &quot;TYu8zw5V&quot; ## [5] &quot;OuRpjoOg0&quot; &quot;p0CubNR2yQ&quot; &quot;xtdycKLOm2k&quot; &quot;fAGVfylZqBGp&quot; ## [9] &quot;gE28DTCi0NV0a&quot; &quot;9MemYE55If0Cvv&quot; Перемешивает символы внутри строки stri_rand_shuffle(&quot;любя, съешь щипцы, — вздохнёт мэр, — кайф жгуч&quot;) ## [1] &quot;,цо м,пюзгу сл аиъ—в кжряд,ыщьчебэн х—штё фй&quot; stri_rand_shuffle(month.name) ## [1] &quot;aJayunr&quot; &quot;eyrbraFu&quot; &quot;achMr&quot; &quot;Aplri&quot; &quot;ayM&quot; &quot;Jnue&quot; ## [7] &quot;uJly&quot; &quot;usuAgt&quot; &quot;tpebermSe&quot; &quot;tOecrbo&quot; &quot;oeNembvr&quot; &quot;Dmceerbe&quot; Генерирует псевдорандомный текст 1 stri_rand_lipsum(nparagraphs = 2) ## [1] &quot;Lorem ipsum dolor sit amet, donec sit nunc urna sed ultricies ac pharetra orci luctus iaculis, ac tincidunt cum. Neque eu semper at sociosqu hendrerit. Eu aliquet lacus, eu hendrerit donec aliquam eros. Risus nibh, quam in sit facilisi ipsum. Amet sem sed donec sed molestie scelerisque tincidunt. Nisl donec et facilisis interdum non sed dolor purus. In ipsum dignissim torquent velit nec aliquam pellentesque. Ac, adipiscing, neque et at torquent, vestibulum ullamcorper. Ad dictumst enim velit non nulla felis habitant. Egestas placerat consectetur, dictum nostra sed nec. Erat phasellus dolor libero aliquam viverra. Vestibulum leo et. Suscipit egestas in in montes, sapien gravida? Conubia purus varius ut nec feugiat.&quot; ## [2] &quot;Risus eleifend magnis neque diam, suspendisse ullamcorper nulla adipiscing malesuada massa, nisi sociosqu velit id et. Aliquam facilisis et aenean. Parturient vel ac in convallis, massa diam nibh. Nulla interdum cursus et. Natoque amet, ut praesent. Tortor ultrices a consectetur, augue natoque class faucibus? Ut sed arcu elementum magna. Dignissim ac facilisi quis ut nisl eu, massa.&quot; 3.3 Соединение и разделение строк Соединенить строки можно используя функцию str_c(), в которую, как и в функции с(), можно перечислять элементы через запятую: tibble(upper = rev(LETTERS), smaller = letters) %&gt;% mutate(merge = str_c(upper, smaller)) Кроме того, если хочется, можно использовать особенный разделитель, указав его в аргументе sep: tibble(upper = rev(LETTERS), smaller = letters) %&gt;% mutate(merge = str_c(upper, smaller, sep = &quot;_&quot;)) Аналогичным образом, для разделение строки на подстроки можно использовать функцию separate(). Это функция разносит разделенные элементы строки в соответствующие столбцы. У функции три обязательных аргумента: col — колонка, которую следует разделить, into — вектор названий новых столбец, sep — разделитель. tibble(upper = rev(LETTERS), smaller = letters) %&gt;% mutate(merge = str_c(upper, smaller, sep = &quot;_&quot;)) %&gt;% separate(col = merge, into = c(&quot;column_1&quot;, &quot;column_2&quot;), sep = &quot;_&quot;) Кроме того, есть инструмент str_split(), которая позволяет разбивать строки на подстроки, но возвращает список. str_split(month.name, &quot;r&quot;) ## [[1]] ## [1] &quot;Janua&quot; &quot;y&quot; ## ## [[2]] ## [1] &quot;Feb&quot; &quot;ua&quot; &quot;y&quot; ## ## [[3]] ## [1] &quot;Ma&quot; &quot;ch&quot; ## ## [[4]] ## [1] &quot;Ap&quot; &quot;il&quot; ## ## [[5]] ## [1] &quot;May&quot; ## ## [[6]] ## [1] &quot;June&quot; ## ## [[7]] ## [1] &quot;July&quot; ## ## [[8]] ## [1] &quot;August&quot; ## ## [[9]] ## [1] &quot;Septembe&quot; &quot;&quot; ## ## [[10]] ## [1] &quot;Octobe&quot; &quot;&quot; ## ## [[11]] ## [1] &quot;Novembe&quot; &quot;&quot; ## ## [[12]] ## [1] &quot;Decembe&quot; &quot;&quot; 3.4 Количество символов 3.4.1 Подсчет количества символов tibble(mn = month.name) %&gt;% mutate(n_charactars = str_count(mn)) 3.4.2 Подгонка количества символов Можно обрезать строки, используя функцию str_trunc(): tibble(mn = month.name) %&gt;% mutate(mn_new = str_trunc(mn, 6)) Можно решить с какой стороны обрезать, используя аргумент side: tibble(mn = month.name) %&gt;% mutate(mn_new = str_trunc(mn, 6, side = &quot;left&quot;)) tibble(mn = month.name) %&gt;% mutate(mn_new = str_trunc(mn, 6, side = &quot;center&quot;)) Можно заменить многоточие, используя аргумент ellipsis: tibble(mn = month.name) %&gt;% mutate(mn_new = str_trunc(mn, 3, ellipsis = &quot;&quot;)) Можно наоборот “раздуть” строку: tibble(mn = month.name) %&gt;% mutate(mn_new = str_pad(mn, 10)) Опять же есть аргумент side: tibble(mn = month.name) %&gt;% mutate(mn_new = str_pad(mn, 10, side = &quot;right&quot;)) Также можно выбрать, чем “раздувать строку”: tibble(mn = month.name) %&gt;% mutate(mn_new = str_pad(mn, 10, pad = &quot;.&quot;)) На Pudding вышла статья про английские пабы. Здесь лежит немного обработанный датасет, которые они использовали. Визуализируйте 40 самых частотоных названий пабов в Великобритании, отложив по оси x количество символов, а по оси y – количество баров с таким названием. 📋 список подсказок ➡ 👁 Датасет скачался, что дальше? ➡ Перво-наперво следует создать переменную, в которой бы хранилось количество каждого из баров. 👁 А как посчитать количество баров? ➡ Это можно сделать при помощи функции count(). 👁 Бары пересчитали, что дальше? ➡ Теперь нужно создать новую переменную, где бы хранилась информация о количестве символов. 👁 Все переменные есть, теперь рисуем? ➡ Не совсем. Перед тем как рисовать нужно отфильтровать 50 самых популярных. 👁 Так, все готово, а какие geom_()? ➡ На графике geom_point() и geom_text_repel() из пакета ggrepel. 👁 А-а-а-а! could not find function \"geom_text_repel\" ➡ А вы включили библиотеку ggrepel? Если не включили, то функция, естественно будет недоступна. 👁 А-а-а-а! geom_text_repel requires the following missing aesthetics: label\" ➡ Все, как написала программа: чтобы писать какой-то текст в функции aes() нужно добавить аргумент label = pub_name. Иначе откуда он узнает, что ему писать? 👁 Фуф! Все готово! ➡ А оси подписаны? А заголовок? А подпись про источник данных? 3.5 Сортировка Для сортировки существует базовая функция sort() и функция из stringr str_sort(): unsorted_latin &lt;- c(&quot;I&quot;, &quot;♥&quot;, &quot;N&quot;, &quot;Y&quot;) sort(unsorted_latin) ## [1] &quot;♥&quot; &quot;I&quot; &quot;N&quot; &quot;Y&quot; str_sort(unsorted_latin) ## [1] &quot;♥&quot; &quot;I&quot; &quot;N&quot; &quot;Y&quot; str_sort(unsorted_latin, locale = &quot;lt&quot;) ## [1] &quot;♥&quot; &quot;I&quot; &quot;Y&quot; &quot;N&quot; unsorted_cyrillic &lt;- c(&quot;я&quot;, &quot;i&quot;, &quot;ж&quot;) str_sort(unsorted_cyrillic) ## [1] &quot;i&quot; &quot;ж&quot; &quot;я&quot; str_sort(unsorted_cyrillic, locale = &quot;ru_UA&quot;) ## [1] &quot;ж&quot; &quot;я&quot; &quot;i&quot; Список локалей на копмьютере можно посмотреть командой stringi::stri_locale_list(). Список всех локалей вообще приведен на этой странице. Еще полезные команды: stringi::stri_locale_info и stringi::stri_locale_set. Не углубляясь в разнообразие алгоритмов сортировки, отмечу, что алгоритм по-умолчанию хуже работает с большими данными: set.seed(42) huge &lt;- sample(letters, 1e7, replace = TRUE) head(huge) ## [1] &quot;q&quot; &quot;e&quot; &quot;a&quot; &quot;y&quot; &quot;j&quot; &quot;d&quot; system.time( sort(huge) ) ## user system elapsed ## 6.982 0.032 7.056 system.time( sort(huge, method = &quot;radix&quot;) ) ## user system elapsed ## 0.319 0.040 0.359 system.time( str_sort(huge) ) ## user system elapsed ## 6.628 0.052 6.681 huge_tbl &lt;- tibble(huge) system.time( huge_tbl %&gt;% arrange(huge) ) ## user system elapsed ## 34.507 0.052 34.560 Предварительный вывод: для больших данных – sort(..., method = \"radix\"). 3.6 Поиск подстроки Можно использовать функцию str_detect(): tibble(mn = month.name) %&gt;% mutate(has_r = str_detect(mn, &quot;r&quot;)) Кроме того, существует функция, которая возвращает индексы, а не значения TRUE/FALSE: tibble(mn = month.name) %&gt;% slice(str_which(mn, &quot;r&quot;)) Также можно посчитать количество вхождений какой-то подстроки: tibble(mn = month.name) %&gt;% mutate(has_r = str_count(mn, &quot;r&quot;)) 3.7 Изменение строк 3.7.1 Изменение регистра latin &lt;- &quot;tHe QuIcK BrOwN fOx JuMpS OvEr ThE lAzY dOg&quot; cyrillic &lt;- &quot;лЮбЯ, сЪеШь ЩиПцЫ, — вЗдОхНёТ мЭр, — кАйФ жГуЧ&quot; str_to_upper(latin) ## [1] &quot;THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG&quot; str_to_lower(cyrillic) ## [1] &quot;любя, съешь щипцы, — вздохнёт мэр, — кайф жгуч&quot; str_to_title(latin) ## [1] &quot;The Quick Brown Fox Jumps Over The Lazy Dog&quot; 3.7.2 Выделение подстроки Подстроку в строке можно выделить двумя способами: по индексам функцией str_sub(), и по подстроке функцией str_png(). extract(images/5.07_str_sub.png) tibble(mn = month.name) %&gt;% mutate(mutate = str_sub(mn, start = 1, end = 2)) tibble(mn = month.name) %&gt;% mutate(mutate = str_extract(mn, &quot;r&quot;)) По умолчанию функция str_extract() возвращает первое вхождение подстроки, соответствующей шаблону. Также существует функция str_extract_all(), которая возвращает все вхождения подстрок, соответствующих шаблону, однако возвращает объект типа список. str_extract_all(month.name, &quot;r&quot;) ## [[1]] ## [1] &quot;r&quot; ## ## [[2]] ## [1] &quot;r&quot; &quot;r&quot; ## ## [[3]] ## [1] &quot;r&quot; ## ## [[4]] ## [1] &quot;r&quot; ## ## [[5]] ## character(0) ## ## [[6]] ## character(0) ## ## [[7]] ## character(0) ## ## [[8]] ## character(0) ## ## [[9]] ## [1] &quot;r&quot; ## ## [[10]] ## [1] &quot;r&quot; ## ## [[11]] ## [1] &quot;r&quot; ## ## [[12]] ## [1] &quot;r&quot; 3.7.3 Замена подстроки Существует функция str_replace(), которая позволяет заменить одну подстроку в строке на другую: tibble(mn = month.name) %&gt;% mutate(mutate = str_replace(mn, &quot;r&quot;, &quot;R&quot;)) Как и другие функции str_replace() делает лишь одну замену, чтобы заменить все вхождения подстроки следует использовать функцию str_replace_all(): tibble(mn = month.name) %&gt;% mutate(mutate = str_replace_all(mn, &quot;r&quot;, &quot;R&quot;)) 3.7.4 Удаление подстроки Для удаления подстроки на основе шаблона, используется функция str_remove() и str_remove_all() tibble(month.name) %&gt;% mutate(mutate = str_remove(month.name, &quot;r&quot;)) tibble(month.name) %&gt;% mutate(mutate = str_remove_all(month.name, &quot;r&quot;)) 3.7.5 Транслитерация строк В пакете stringi сууществует достаточно много методов транслитераций строк, которые можно вывести командой stri_trans_list(). Вот пример использования некоторых из них: stri_trans_general(&quot;stringi&quot;, &quot;latin-cyrillic&quot;) ## [1] &quot;стринги&quot; stri_trans_general(&quot;сырники&quot;, &quot;cyrillic-latin&quot;) ## [1] &quot;syrniki&quot; stri_trans_general(&quot;stringi&quot;, &quot;latin-greek&quot;) ## [1] &quot;στριγγι&quot; stri_trans_general(&quot;stringi&quot;, &quot;latin-armenian&quot;) ## [1] &quot;ստրինգի&quot; Вот два датасета: список городов России частотный словарь русского языка [Шаров, Ляшевская 2011] Определите сколько городов называется обычным словом русского языка (например, город Орёл)? Не забудьте поменять ё на е. 📋 список подсказок ➡ 👁 Датасеты скачались, что дальше? ➡ Надо их преобразовать к нужному виду и объединить. 👁 А как их соединить? Что у них общего? ➡ В одном датасете есть переменная city, в другом – переменная lemma. Все города начинаются с большой буквы, все леммы с маленькой буквы. Я бы уменьшил букву в датасете с городами, сделал бы новый столбец в датасете с городами (например, town), соединил бы датасеты и посчитал бы сколько в результирующем датасете значений town. 👁 А как соеднить? ➡ Я бы использовал dict %&gt;% ... %&gt;% inner_join(cities). Если в датасетах разные названия столбцов, то следует указывать какие столбцы, каким соответствуют:dict %&gt;% ... %&gt;% inner_join(cities, by = c(\"lemma\" = \"city\")) 👁 Соединилось вроде… А как посчитать? ➡ Я бы, как обычно, использовал функцию count(). 3.8 Регулярные выражения Большинство функций из раздела об операциях над векторами (str_detect(), str_extract(), str_remove() и т. п.) имеют следующую структуру: строка, с которой работает функция образец (pattern) Дальше мы будем использовать функцию str_view_all(), которая позволяет показывать, выделенное образцом в исходной строке. str_view_all(&quot;Я всегда путаю с и c&quot;, &quot;c&quot;) # я ищу латинскую c 3.8.1 Экранирование метасимволов a &lt;- &quot;Всем известно, что 4$\\\\2 + 3$ * 5 = 17$? Да? Ну хорошо (а то я не был уверен). [|}^{|]&quot; str_view_all(a, &quot;$&quot;) str_view_all(a, &quot;\\\\$&quot;) str_view_all(a, &quot;\\\\.&quot;) str_view_all(a, &quot;\\\\*&quot;) str_view_all(a, &quot;\\\\+&quot;) str_view_all(a, &quot;\\\\?&quot;) str_view_all(a, &quot;\\\\(&quot;) str_view_all(a, &quot;\\\\)&quot;) str_view_all(a, &quot;\\\\|&quot;) str_view_all(a, &quot;\\\\^&quot;) str_view_all(a, &quot;\\\\[&quot;) str_view_all(a, &quot;\\\\]&quot;) str_view_all(a, &quot;\\\\{&quot;) str_view_all(a, &quot;\\\\}&quot;) str_view_all(a, &quot;\\\\\\\\&quot;) 3.8.2 Классы знаков \\\\d – цифры. \\\\D – не цифры. str_view_all(&quot;два 15 42. 42 15. 37 08 5. 20 20 20!&quot;, &quot;\\\\d&quot;) str_view_all(&quot;два 15 42. 42 15. 37 08 5. 20 20 20!&quot;, &quot;\\\\D&quot;) \\\\s – пробелы. \\\\S – не пробелы. str_view_all(&quot;два 15 42. 42 15. 37 08 5. 20 20 20!&quot;, &quot;\\\\s&quot;) str_view_all(&quot;два 15 42. 42 15. 37 08 5. 20 20 20!&quot;, &quot;\\\\S&quot;) \\\\w – не пробелы и не знаки препинания. \\\\W – пробелы и знаки препинания. str_view_all(&quot;два 15 42. 42 15. 37 08 5. 20 20 20!&quot;, &quot;\\\\w&quot;) str_view_all(&quot;два 15 42. 42 15. 37 08 5. 20 20 20!&quot;, &quot;\\\\W&quot;) произвольная группа символов и обратная к ней str_view_all(&quot;Умей мечтать, не став рабом мечтанья&quot;, &quot;[оауиыэёеяю]&quot;) str_view_all(&quot;И мыслить, мысли не обожествив&quot;, &quot;[^оауиыэёеяю]&quot;) встроенные группы символов str_view_all(&quot;два 15 42. 42 15. 37 08 5. 20 20 20!&quot;, &quot;[0-9]&quot;) str_view_all(&quot;Карл у Клары украл кораллы, а Клара у Карла украла кларнет&quot;, &quot;[а-я]&quot;) str_view_all(&quot;Карл у Клары украл кораллы, а Клара у Карла украла кларнет&quot;, &quot;[А-Я]&quot;) str_view_all(&quot;Карл у Клары украл кораллы, а Клара у Карла украла кларнет&quot;, &quot;[А-я]&quot;) str_view_all(&quot;The quick brown Fox jumps over the lazy Dog&quot;, &quot;[a-z]&quot;) str_view_all(&quot;два 15 42. 42 15. 37 08 5. 20 20 20!&quot;, &quot;[^0-9]&quot;) выбор из нескольких групп str_view_all(&quot;Карл у Клары украл кораллы, а Клара у Карла украла кларнет&quot;, &quot;лар|рал|арл&quot;) произвольный символ str_view_all(&quot;Везет Сенька Саньку с Сонькой на санках. Санки скок, Сеньку с ног, Соньку в лоб, все — в сугроб&quot;, &quot;[Сс].н&quot;) знак начала и конца строки str_view_all(&quot;от топота копыт пыль по полю летит.&quot;, &quot;^о&quot;) str_view_all(&quot;У ежа — ежата, у ужа — ужата&quot;, &quot;жата$&quot;) есть еще другие группы и другие обозначения уже приведенных групп, см. ?regex 3.8.3 Квантификация ? – ноль или один раз str_view_all(&quot;хорошее длинношеее животное&quot;, &quot;еее?&quot;) * – ноль и более раз str_view_all(&quot;хорошее длинношеее животное&quot;, &quot;ее*&quot;) + – один и более раз str_view_all(&quot;хорошее длинношеее животное&quot;, &quot;е+&quot;) {n} – n раз str_view_all(&quot;хорошее длинношеее животное&quot;, &quot;е{2}&quot;) {n,} – n раз и более str_view_all(&quot;хорошее длинношеее животное&quot;, &quot;е{1,}&quot;) {n,m} – от n до m. Отсутствие пробела важно: {1,2} – правильно, {1,␣2} – неправильно. str_view_all(&quot;хорошее длинношеее животное&quot;, &quot;е{2,3}&quot;) группировка символов str_view_all(&quot;Пушкиновед, Лермонтовед, Лермонтововед&quot;, &quot;(ов)+&quot;) str_view_all(&quot;беловатый, розоватый, розововатый&quot;, &quot;(ов)+&quot;) жадный vs. нежадный алоритмы str_view_all(&quot;Пушкиновед, Лермонтовед, Лермонтововед&quot;, &quot;в.*ед&quot;) str_view_all(&quot;Пушкиновед, Лермонтовед, Лермонтововед&quot;, &quot;в.*?ед&quot;) 3.8.4 Позиционная проверка (look arounds) Позиционная проверка – выглядит достаточно непоследовательно даже в свете остальных регулярных выражений. Давайте найдем все а перед р: str_view_all(&quot;Карл у Клары украл кораллы, а Клара у Карла украла кларнет&quot;, &quot;а(?=р)&quot;) А теперь все а перед р или л: str_view_all(&quot;Карл у Клары украл кораллы, а Клара у Карла украла кларнет&quot;, &quot;а(?=[рл])&quot;) Давайте найдем все а после р str_view_all(&quot;Карл у Клары украл кораллы, а Клара у Карла украла кларнет&quot;, &quot;(?&lt;=р)а&quot;) А теперь все а после р или л: str_view_all(&quot;Карл у Клары украл кораллы, а Клара у Карла украла кларнет&quot;, &quot;(?&lt;=[рл])а&quot;) Также у этих выражений есть формы с отрицанием. Давайте найдем все р не перед а: str_view_all(&quot;Карл у Клары украл кораллы, а Клара у Карла украла кларнет&quot;, &quot;р(?!а)&quot;) А теперь все р не после а: str_view_all(&quot;Карл у Клары украл кораллы, а Клара у Карла украла кларнет&quot;, &quot;(?&lt;!а)р&quot;) Запомнить с ходу это достаточно сложно, так что подсматривайте сюда: Вот отсюда можно скачать файл с текстом стихотворения Н. Заболоцкого “Меркнут знаки задиака”. Посчитайте долю женских (ударение падает на предпоследний слог рифмующихся слов) и мужских (ударение падает на последний слог рифмующихся слов) рифм в стихотворении. 📋 список подсказок ➡ 👁 Датасеты скачивается с ошибкой, почему? ➡ Дело в том, что исходный файл в формате .txt, а не .csv. Его нужно скачивать, например, командой read_lines() 👁 Ошибка: ...applied to an object of class \"character\" ➡ Скачав файл Вы получили вектор со строками, где каждая элимент вектора – строка стихотворения. Создайте tibble(), тогда можно будет применять стандартные инструменты tidyverse. 👁 Хорошо, tibble() создан, что дальше? ➡ Дальше нужно создать переменную, из которой будет понятно, мужская в каждой строке рифма, или женская. 👁 А как определить, какая рифма? Нужно с словарем сравнивать? ➡ Формально говоря, определять рифму можно по косвенным признакам. Все стихотворение написано четырехстопным хореем, значит в нем либо 7, либо 8 слогов. Значит, посчитав количество слогов, мы поймем, какая перед нами рифма. 👁 А как посчитать гласные? ➡ Нужно написать регулярное выражение… вроде бы это тема нашего занятия… 👁 Гласные посчитаны. А что дальше? ➡ Ну теперь нужно посчитать, сколько каких длин (в количестве слогов) бывает в стихотворении. Это можно сделать при помощи функции count(). 👁 А почему у меня есть строки длины 0 слогов ➡ Ну, видимо, в стихотворении были пустые строки. Они использовались для разделения строф. 👁 А почему у меня есть строки длины 6 слогов ➡ Ну, видимо, Вы написали регулярное выражение, которое не учитывает, что гласные буквы могут быть еще и в начале строки, а значит написаны с большой буквы. В ходе анализа данных чаще всего бороться со строками и регулярными выражениями приходится в процессе обработки неаккуратнособранных анкет. Предлагаю обработать переменные sex и age такой вот неудачно собранной анкеты и построить следующий график: 📋 список подсказок ➡ 👁 А что это за geom_...()? ➡ Это geom_dotplot() с аргументом method = \"histodot\" и с удаленной осью y при помощи команды scale_y_continuous(NULL, breaks = NULL) 👁 Почему на графике рисутеся каждое значение возраста? ➡ Если Вы все правильно преобразовали, должно помочь преобразование строковой переменной age в числовую при помощи функции as.integer(). 3.9 Определение языка Для определения языка существует два пакета cld2 (вероятностный) и cld3 (нейросеть). udhr_24 &lt;- read_csv(&quot;https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/article_24_from_UDHR.csv&quot;) ## Rows: 6 Columns: 1 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): article_text ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. udhr_24 cld2::detect_language(udhr_24$article_text) ## [1] &quot;ru&quot; &quot;en&quot; &quot;fr&quot; &quot;es&quot; &quot;ar&quot; &quot;zh&quot; cld2::detect_language(udhr_24$article_text, lang_code = FALSE) ## [1] &quot;RUSSIAN&quot; &quot;ENGLISH&quot; &quot;FRENCH&quot; &quot;SPANISH&quot; &quot;ARABIC&quot; &quot;CHINESE&quot; cld3::detect_language(udhr_24$article_text) ## [1] &quot;ru&quot; &quot;en&quot; &quot;fr&quot; &quot;es&quot; &quot;ar&quot; &quot;zh&quot; cld2::detect_language(&quot;Ты женат? Говорите ли по-английски?&quot;) ## [1] &quot;bg&quot; cld3::detect_language(&quot;Ты женат? Говорите ли по-английски?&quot;) ## [1] NA cld2::detect_language(&quot;Варкалось. Хливкие шорьки пырялись по наве, и хрюкотали зелюки, как мюмзики в мове.&quot;) ## [1] &quot;ru&quot; cld3::detect_language(&quot;Варкалось. Хливкие шорьки пырялись по наве, и хрюкотали зелюки, как мюмзики в мове.&quot;) ## [1] &quot;ru&quot; cld2::detect_language(&quot;Варчилось… Хлив&#39;язкі тхурки викрули, свербчись навкрузі, жасумновілі худоки гривіли зехряки в чузі.&quot;) ## [1] &quot;uk&quot; cld3::detect_language(&quot;Варчилось… Хлив&#39;язкі тхурки викрули, свербчись навкрузі, жасумновілі худоки гривіли зехряки в чузі.&quot;) ## [1] &quot;uk&quot; cld2::detect_language_mixed(&quot;Многие в нашей команде OpenDataScience занимаются state-of-the-art технологиями машинного обучения: DL-фреймворками, байесовскими методами машинного обучения, вероятностным программированием и не только.&quot;) ## $classification ## language code latin proportion ## 1 RUSSIAN ru FALSE 0.87 ## 2 ENGLISH en TRUE 0.11 ## 3 UNKNOWN un TRUE 0.00 ## ## $bytes ## [1] 353 ## ## $reliabale ## [1] TRUE cld3::detect_language_mixed(&quot;Многие в нашей команде OpenDataScience занимаются state-of-the-art технологиями машинного обучения: DL-фреймворками, байесовскими методами машинного обучения, вероятностным программированием и не только.&quot;) 3.10 Расстояния между строками Существует много разных метрик для измерения расстояния между строками (см. ?`stringdist-metrics`), в примерах используется расстояние Дамерау — Левенштейна. Данное расстояние получается при подсчете количества операций, которые нужно сделать, чтобы перевести одну строку в другую. вставка ab → aNb удаление aOb → ab замена символа aOb → aNb перестановка символов ab → ba library(stringdist) ## ## Attaching package: &#39;stringdist&#39; ## The following object is masked from &#39;package:tidyr&#39;: ## ## extract stringdist(&quot;корова&quot;,&quot;корова&quot;) ## [1] 0 stringdist(&quot;коровы&quot;, c(&quot;курица&quot;, &quot;бык&quot;, &quot;утка&quot;, &quot;корова&quot;, &quot;осел&quot;)) ## [1] 4 6 6 1 5 amatch(c(&quot;быки&quot;, &quot;коровы&quot;), c(&quot;курица&quot;, &quot;бык&quot;, &quot;утка&quot;, &quot;корова&quot;, &quot;осел&quot;), maxDist = 2) ## [1] 2 4 3.11 Дополнительные задания: В датасет записаны твиты Донольда Трампа взятые с kaggle. Постройте график рассеяния, которые показывает связь количества ретвитов и лайков. Чтобы убрать научную запись больших чисел используйте команду options(scipen = 999). Постройте гистограмму, которая показывает распределения длины твитов в символах. Какой метод определения размера ячейки использован на приведенном графике? [Sturgers 1926], [Scott 1979] или [Freedman, Diaconis 1981]? Постройте график рассеивания, который бы показывал связь с длиной твита во времени. Используя geom_hline(), наложите две линии: 140 символов и 280. Сделайте прозрачность 0.1. Постройте график рассеивания, который бы показывал связь с длиной твита во времени. Разбейте и раскрасьте твиты на основании наличия в них интернет ссылок. Можно ли утверждать, что твиты со ссылками длиннее? Постройте вайолинплот, которые показывает распределение значений длины твитов в зависимости от наличия в них интернет ссылок. Найдите твиты которые содержат корень america, которые встречаются больше одного раза, и фасетизируйте по таким словам. Lorem ipsum — классический текст-заполнитель на основе трактата Марка Туллия Цицерона “О пределах добра и зла”. Его используют, чтобы посмотреть, как страница смотриться, когда заполнена текстом↩︎ "],["data_presentation.html", "4 Представление данных: rmarkdown 4.1 rmarkdown 4.2 Бывают и другие способы представления данных", " 4 Представление данных: rmarkdown Достаточно важной частью работы с данными является их представление. Мы рассмотрим наиболее распространенный варианты: rmarkdown, flexdashboard и shiny. Смотрите книжку Xie, Allaire, and Grolemund (2019) или cheatsheet. 4.1 rmarkdown rmarkdown – это пакет, который позволяет соединять R команды и их исполнения в один документ. В результате можно комбинировать текст и исполняемый код, что в свою очередь позволяет делать: * докумунты в формате .html, .pdf (используя , мы почти не будем это обсуждать), .docx * презентации в формате .html, .pdf (используя пакет beamer) .pptx-презентации * набор связанных .html документов (полноценный сайт или книга) 4.1.1 Установка Как и все пакеты rmarkdown можно установить из CRAN install.packages(&quot;rmarkdown&quot;) 4.1.2 Составляющие rmarkdown-документа yaml шапка (факультативна) обычный текст с markdown форматированием (расширенный при помощи Pandoc) блоки кода (не обязательно на языке R), оформленные с двух сторон тройным бэктиком ``` (у меня на клавиатуре этот знак на букве ё). 4.1.3 Пример rmarkdown-документа Создайте файл .Rmd в какой-нибудь папке (в RStudio, это можно сделать File &gt; New file &gt; R Markdown). Скомпелировать файл можно командой: rmarkdown::render(&quot;ваш_файл.Rmd&quot;) или кнопкой . Вот пример кода: --- output: html_document --- ## Данные В документе можно вставлять R код ```{r} summary(iris) ``` ## График И строить графики ```{r} library(tidyverse) iris %&gt;% ggplot(aes(Sepal.Length, Sepal.Width))+ geom_point() ``` Результат. Создайте и скомпелируйте свой rmarkdown-документ с заголовком, текстом и кодом. 4.1.4 Markdown Универсальны язык разметки, работает во многих современных он-лайн системах создания текста. 4.1.4.1 Заголовки ## Заголовок уровня 2 #### Заголовок уровня 4 4.1.4.2 Форматирование _италик_ или *другой италик* __жирный__ или **другой жирный** ~~зачеркивание~~ италик или другой италик жирный или другой жирный зачеркивание 4.1.4.3 Списки * кролик * заяц * заяц серый 1. машины 1. автобус 2. самолеты + можно еще ставить плюс - и минус кролик заяц заяц серый машины автобус самолеты можно еще ставить плюс и минус 4.1.4.4 Ссылки и картинки [Ссылка 1](https://agricolamz.github.io/2018_ANDAN_course_winter/2_ex.html) &lt;https://agricolamz.github.io/2018_ANDAN_course_winter/2_ex.html&gt; [Можно вставить ссылку потом, а пока отсавить метку][1] Или даже просто голую [метку]. ![](https://raw.githubusercontent.com/agricolamz/2018_ANDAN_course_winter/master/rmarkdown.png) Опять же можно вставить только метку ![][2] [1]: https://agricolamz.github.io/2018_ANDAN_course_winter/2_ex.html [метку]: https://agricolamz.github.io/2018_ANDAN_course_winter/2_ex.html [2]: https://raw.githubusercontent.com/agricolamz/2018_ANDAN_course_winter/master/rmarkdown.png Ссылка 1 https://agricolamz.github.io/2018_ANDAN_course_winter/2_ex.html Можно вставить ссылку потом, а пока отсавить метку Или даже просто голую метку. Опять же можно вставить только метку 4.1.4.5 Код Код нужно оформалять вот так `rmarkdown::render()` Код нужно оформалять вот так rmarkdown::render() ```{python} friends = [&#39;john&#39;, &#39;pat&#39;, &#39;gary&#39;, &#39;michael&#39;] for i, name in enumerate(friends): print &quot;iteration {iteration} is {name}&quot;.format(iteration=i, name=name) ``` collection = [&#39;hey&#39;, 5, &#39;d&#39;] for x in collection: print(x) hey 5 d Если хочется использовать результат работы кода в тексте, нужно в начале поставить язык, который будет исполнять код, например, в Фигурные скобки не обязательны, но тогда RStudio подсветит. 4.1.4.6 Цитаты &gt; Цитаты нужно офрмлять так. &gt; Это попадет в тот же фрагмент. &gt; А вот тут произошел разрыв. Кстати, здесь тоже можно использовать *markdown*. Цитаты нужно офрмлять так. Это попадет в тот же фрагмент. А вот тут произошел разрыв. Кстати, здесь тоже можно использовать markdown. 4.1.4.7 Разрыв страницы *** 4.1.4.8 HTML &lt;dl&gt; &lt;dt&gt;Чистый HTML&lt;/dt&gt; &lt;dd&gt;Еще можно писать в HTML.&lt;/dd&gt; &lt;dt&gt;и Markdown в HTML &lt;/dt&gt; &lt;dd&gt; даже работает **правильно**. Но можно использовать и &lt;em&gt;теги&lt;/em&gt;.&lt;/dd&gt; &lt;/dl&gt; Чистый HTML Еще можно писать в HTML. и Markdown в HTML даже работает правильно. Но можно использовать и теги. 4.1.4.9 Таблицы Еще есть целая наука как делать таблицы в Markdown, но я предпочитаю использовать он-лайн генератор. 4.1.5 Pandoc Pandoc это программа, созданная Дж. МакФарлэйном (J. MacFarlane), которая позволяет переходить из разных текстовых форматов в другие, а также смешивать их. Я покожу лишь несколько полезных расширений. 4.1.5.1 Верхние и нижние индексы 2^10^ C~n~^k^ 210 Cnk 4.1.5.2 Нумерованные примеры (@) Славный пример номер раз. (@) Славный пример номер два. (@three) Славный пример номер три, у которого есть *имя*. Я могу сослаться на пример (@three)! Славный пример номер раз. Славный пример номер два. Славный пример номер три, у которого есть имя. Я могу сослаться на пример (3)! 4.1.5.3 Сноски Вот и сноска[^1] [^1]: Сноска, сноска, сноска. Вот и сноска2 4.1.5.4 Математика: \\(\\LaTeX\\) $\\LaTeX$ код может быть в тексте $\\frac{\\pi}{\\sum{n+1}}$ или отдельной строчкой: $$\\frac{\\pi}{\\sum{n+1}}$$ \\(\\LaTeX\\) код может быть в тексте \\(\\frac{\\pi}{\\sum{n+1}}\\) или отдельной строчкой: \\[\\frac{\\pi}{\\sum{n+1}}\\] 4.1.6 Code chunks Фрагменты кода имеют свои наборы свойств, который можно записывать в фигурных скобках. 4.1.6.1 Язык программирования ```{r} summary(cars) ``` ```{python} x = &quot;my string&quot; print(x.split(&quot; &quot;)) ``` summary(cars) speed dist Min. : 4.0 Min. : 2.00 1st Qu.:12.0 1st Qu.: 26.00 Median :15.0 Median : 36.00 Mean :15.4 Mean : 42.98 3rd Qu.:19.0 3rd Qu.: 56.00 Max. :25.0 Max. :120.00 x = &quot;my string&quot; print(x.split(&quot; &quot;)) [&#39;my&#39;, &#39;string&#39;] 4.1.6.2 Появление и исполнение кода И код, и результат ```{r} plot(mtcars$mpg) ``` Только результат ```{r, echo = FALSE} plot(mtcars$mpg) ``` Только код ```{r, eval = FALSE} plot(mtcars$mpg) ``` Исполняется, но не показывается ни код, ни результат ```{r, include = FALSE} a &lt;- mtcars$mpg ``` Обратимся к переменной, созданной в фрагменте с аргументом `include = FALSE` ```{r} a ``` 4.1.6.3 Другие полезные аргументы Существует достаточно много аргументов, которые можно перечислить в фигурных скобках в фрагменте кода, вот некоторые из них: error: показывать ли ошибки. warning: показывать ли предупреждения. message: показывать ли сообщения (например, при подключении пакетов). comment: по умолчанию, результат работы кода предваряется знаком ##, используйте NA, чтобы их не было, или любую другую строку. cache: сохранить ли результат работы фрагмента кода. Очень полезно, если происходят какие-то операции, занимающая много времени. Сохранив результат, не нужно будет тратить время, на пересчет, при каждой новой компиляции. fig.width, fig.height (по умолчанию, 7) Все эти аргументы можно перечислить в функции knitr::opts_chunk$set(...): 4.1.6.4 Pets or livestock? В RMarkdown каждому фрагменту кода можно дать имя (но избегайте пробелов и точек): ```{r my_beautiful_graph, eval = FALSE} library(tidyverse) diamonds %&gt;% count(carat, color) %&gt;% ggplot(aes(carat, n, color = color))+ geom_point() ``` Maëlle Salmon написал отличный пост, почему полезно именовать фрагменты кода: проще ориентироваться код более читаемый ошибки при компеляции показывают имя, а не номер если фрагмент кэшировался, то добавление одного фрагменты перед ним, не заставит все пересчитываться в blogdown можно ссылаться 4.1.7 YAML шапка Факультативная YAML шапка обычно содержит метаданные документа, и аргументы, необходимые для работы некоторых дополнений. --- title: &quot;Мой RMarkdown&quot; author: Славный Автор date: 20 ноября 2019 --- 4.1.7.1 Тип получившегося файла output: html_document (по умолчанию) output: word_document output: pdf_document (но нужно договориться с \\(\\LaTeX\\)ом на вашем компьютере) output: ioslides_presentation output: slidy_presentation output: slidy_presentation output: beamer_presentation и др. 4.1.7.2 Библиография Существует несколько сопособов вставлять библиографию в RMarkdown. Я раскажу, как использовать пакет Bibtex (как видно из названия, сделанный для \\(\\LaTeX\\)). Для начала нужно создать файл с раширением .bib, в который записать все источники, которые будут использоваться (библиографию в формате BibTeX выдает, например, GoogleScholar): @book{ladefoged96, title={The sounds of the world&#39;s languages}, author={Ladefoged, P. and Maddieson, I.}, year={1996}, publisher={Oxford Publishers} } @article{gordon02, title={A cross-linguistic acoustic study of voiceless fricatives}, author={Gordon, M. and Barthmaier, P. and Sands, K.}, journal={Journal of the International Phonetic Association}, volume={32}, number={2}, pages={141--174}, year={2002}, publisher={Cambridge University Press} } На следующем шаге нужно добавить название файла с раширением .bib в YAML шапку: --- bibliography: bibliography.bib --- После этого, можно использовать сслыки в тексте В своей работе @gordon02 раскрыл... В своей работе Gordon, Barthmaier, and Sands (2002) раскрыл… Об этом можно узнать из [@ladefoged96; @gordon02], но ... Об этом можно узнать из (Ladefoged and Maddieson 1996; Gordon, Barthmaier, and Sands 2002), но … В своей работе [@gordon02] раскрыл... В своей работе (Gordon, Barthmaier, and Sands 2002) раскрыл… Об этом можно узнать из [см. @gordon02, с. 33--35; а также @ladefoged96, гл. 1]... Об этом можно узнать из (см. Gordon, Barthmaier, and Sands 2002, с. 33–35; а также Ladefoged and Maddieson 1996, гл. 1)… Список литературы автоматически появляется в конце. 4.1.7.3 Оглавление и пр. Существует сразу несколько аргументов, отвечающих за оглавление. toc вставлять ли оглавление toc_depth глубина иерархии, которую отражать в огловлении toc_float должно ли оглавление все время следовать за текстом collapsed должно ли оглавление быть все время полностью раскрыто collapsed должно ли оглавление быть все время полностью раскрыто number_sections автоматическая нумерация секций code_folding (hide) — делать ли кнопочку, показывающую/скрывающую весь код theme одна из Bootstrap тем highlight: “default”, “tango”, “pygments”, “kate”, “monochrome”, “espresso”, “zenburn”, “haddock” или “textmate” --- html_document: theme: spacelab highlight: pygments toc: yes toc_position: right toc_depth: 3 toc_float: yes smooth_scroll: false --- 4.1.7.4 Отображение датафреймов df_print: default df_print: kable df_print: tibble df_print: paged --- output: html_document: df_print: paged --- 4.1.8 Где хостить .html? Полученные .html можно разместить в интернете: на каком-то вашем хосте опубликовать на бесплатном хостинке Rpubs опубликовать на гитхабе и включить Github Pages Теперь создайте документ index.Rmd, в котором напишите код на R и на Python, вставьте картинку, сноску, ссылку на литературу, таблицу и оглавление. Скомпелируйте .html документ и опубликуйте его на Github, пройдя по этой ссылке. Cделайте Github Pages и заполните README.md файл. 4.2 Бывают и другие способы представления данных flexdashboard – динамические дэшборды shiny – динамические сайты, которые позволяют взаимодействовать с пользователем posterdown – постеры в RMarkdown pagedown – содержит много шаблонов: для книги, статьи, постера, резюме, визитки… да хоть приглашение на свадьбу можно сделать. Ссылки на литературу "],["работа-с-текстами-gutenbergr-tidytext-stopwords.html", "5 Работа с текстами: gutenbergr, tidytext, stopwords 5.1 Загрузка текста в R 5.2 Пакет gutenbergr 5.3 Библиотека tidytext 5.4 Пакет stopwords", " 5 Работа с текстами: gutenbergr, tidytext, stopwords library(tidyverse) 5.1 Загрузка текста в R В пакете readr (входит в tidyverse) для чтения текста есть функция read_lines(). В качестве первой переменной может выступать путь к файлу на компьютере или интернет ссылка: t &lt;- read_lines(&quot;https://raw.githubusercontent.com/agricolamz/2020_HSE_DPO/master/data/Chang.txt&quot;) head(t) [1] &quot;Тед Чан&quot; [2] &quot;История твоей жизни&quot; [3] &quot;Твой отец собирается задать мне вопрос. Это самый важный момент в нашей жизни, и я хочу&quot; [4] &quot;запомнить все до малейшей детали. Уже за полночь, но мы только что вернулись домой после&quot; [5] &quot;ужина в ресторане и веселого шоу и сразу выходим в патио полюбоваться полной луной. Хочу&quot; [6] &quot;танцевать! — объявляю я, и твой отец подтрунивает надо мной, но мы начинаем скользить в&quot; Тексты хранятся в интернете по разному. Часто бывает так, что текст дигитализировали так, как он напечатан, так что в результате каждая строка в печатной книжке соответствует строке в текстовом файле (так, например, в нашем примере). Такой файл следует склеить воедино, используя пробел в качестве разделителя: t2 &lt;- str_c(t, collapse = &quot; &quot;) length(t2) [1] 1 str_length(t2) [1] 117398 При таком слиянии, стоит проверить, не было ли в анализируемом тексте знаков переноса, иначе они сольются неправильно: str_c(c(&quot;... она запо-&quot;, &quot;лучила ...&quot;), collapse = &quot; &quot;) [1] &quot;... она запо- лучила ...&quot; 5.2 Пакет gutenbergr Пакет gutenbergr является API для очень старого проекта Gutenberg. library(gutenbergr) Все самое важное в этом пакете хранится в датасете gutenberg_metadata str(gutenberg_metadata) tibble [51,997 × 8] (S3: tbl_df/tbl/data.frame) $ gutenberg_id : int [1:51997] 0 1 2 3 4 5 6 7 8 9 ... $ title : chr [1:51997] NA &quot;The Declaration of Independence of the United States of America&quot; &quot;The United States Bill of Rights\\r\\nThe Ten Original Amendments to the Constitution of the United States&quot; &quot;John F. Kennedy&#39;s Inaugural Address&quot; ... $ author : chr [1:51997] NA &quot;Jefferson, Thomas&quot; &quot;United States&quot; &quot;Kennedy, John F. (John Fitzgerald)&quot; ... $ gutenberg_author_id: int [1:51997] NA 1638 1 1666 3 1 4 NA 3 3 ... $ language : chr [1:51997] &quot;en&quot; &quot;en&quot; &quot;en&quot; &quot;en&quot; ... $ gutenberg_bookshelf: chr [1:51997] NA &quot;United States Law/American Revolutionary War/Politics&quot; &quot;American Revolutionary War/Politics/United States Law&quot; NA ... $ rights : chr [1:51997] &quot;Public domain in the USA.&quot; &quot;Public domain in the USA.&quot; &quot;Public domain in the USA.&quot; &quot;Public domain in the USA.&quot; ... $ has_text : logi [1:51997] TRUE TRUE TRUE TRUE TRUE TRUE ... - attr(*, &quot;date_updated&quot;)= Date[1:1], format: &quot;2016-05-05&quot; Например, сейчас мы можем понять, сколько книг на разных языках можно скачать из проекта: gutenberg_metadata %&gt;% count(language, sort = TRUE) Как видно, в основном это тексты на английском. Сколько авторов в датасете? gutenberg_metadata %&gt;% count(author, sort = TRUE) Сколько произведений Джейн Остин (не перепутайте с другими Остин) есть в датасете? gutenberg_metadata %&gt;% filter(author == &quot;Austen, Jane&quot;) %&gt;% distinct(gutenberg_id, title) Давайте скачаем “Эмму”: emma &lt;- gutenberg_download(158) Determining mirror for Project Gutenberg from http://www.gutenberg.org/robot/harvest Using mirror http://aleph.gutenberg.org emma Можно скачивать сразу несколько книг. Давайте добавим еще “Леди Сьюзен”: books &lt;- gutenberg_download(c(158, 946), meta_fields = &quot;title&quot;) books books %&gt;% count(title) Сколько уникальных заголовков из базы данных содержит “Sherlock Holmes”? Скачайте все произведения Гертруды Стайн (по-английски, она Gertrude Stein) из базы данных и вставьте название самого длинного текста. 5.3 Библиотека tidytext Сейчас скачанные книги записаны в таблицу, где одна строка это один абзац. Хочется мочь посчитать слова. Для этого книги нужно привести в tidy формат и для этого написан пакет tidytext (онлайн книга доступна здесь). Основное “оружие” пакета tidytext функция unnest_tokens(), которая переводит текст в tidy формат. В аргумент output подается вектор с именем будущей переменной, а аргумент input принимает переменную с текстом. library(tidytext) books %&gt;% unnest_tokens(output = &quot;word&quot;, input = text) Теперь можно посчитать самые частотные слова в обоих произведениях: books %&gt;% unnest_tokens(output = &quot;word&quot;, input = text) %&gt;% count(title, word, sort = TRUE) Ну… Это было ожидаемо. Нужно убрать стопслова. Английские стопслова встроены в пакет (переменная stop_words): books %&gt;% unnest_tokens(word, text) %&gt;% count(title, word, sort = TRUE) %&gt;% anti_join(stop_words) Joining, by = &quot;word&quot; Постройте следующий график, на котором представлены самые частотные 20 слов каждого из произведений. Как видно, на графике все не упорядочено, давайте начнем с такого примера: books %&gt;% unnest_tokens(word, text) %&gt;% count(word, sort = TRUE) %&gt;% slice(1:20) %&gt;% ggplot(aes(n, word))+ geom_col() Если мы работаем с одним фасетом, то все проблемы может решить функция fct_reorder(), которая упорядочивает на основании некоторой переменной: books %&gt;% unnest_tokens(word, text) %&gt;% count(word, sort = TRUE) %&gt;% slice(1:20) %&gt;% mutate(word = fct_reorder(word, n)) %&gt;% ggplot(aes(n, word))+ geom_col() Однако, если мы применим это к нашим данным, то получится неупорядочено: books %&gt;% unnest_tokens(word, text) %&gt;% count(title, word, sort = TRUE) %&gt;% group_by(title) %&gt;% slice(1:20) %&gt;% ungroup() %&gt;% mutate(word = fct_reorder(word, n)) %&gt;% ggplot(aes(n, word))+ geom_col()+ facet_wrap(~title, scales = &quot;free&quot;) В пакете tidytext есть функция reorder_within(), которая позволяет упорядочить нужным образом: books %&gt;% unnest_tokens(word, text) %&gt;% count(title, word, sort = TRUE) %&gt;% group_by(title) %&gt;% slice(1:20) %&gt;% ungroup() %&gt;% mutate(word = reorder_within(x = word, by = n, within = title)) %&gt;% ggplot(aes(n, word))+ geom_col()+ facet_wrap(~title, scales = &quot;free&quot;) Чтобы избавиться от дополнительной подписи нужно использовать scale_y_reordered() или scale_x_reordered(): books %&gt;% unnest_tokens(word, text) %&gt;% count(title, word, sort = TRUE) %&gt;% group_by(title) %&gt;% slice(1:20) %&gt;% ungroup() %&gt;% mutate(word = reorder_within(x = word, by = n, within = title)) %&gt;% ggplot(aes(n, word))+ geom_col()+ facet_wrap(~title, scales = &quot;free&quot;)+ scale_y_reordered() Функция unnest_tokens() позволяет работать не только со словами, но и, напрмиер, с биграммами: books %&gt;% unnest_tokens(word, text, token = &quot;ngrams&quot;, n = 2) Поиск самых частотных слов — не едиснственная задача, которую можно решать при работе с текстом. Иногда имеет смысл узнать распределение слов в произведении. Давайте посмотрим как распределены в романе “Эмма” фамилии главных героев: books %&gt;% filter(title == &quot;Emma&quot;) %&gt;% unnest_tokens(word, text) %&gt;% mutate(narrative_time = 1:n()) %&gt;% filter(str_detect(word, &quot;knightley$|woodhouse$|churchill$|fairfax$&quot;)) %&gt;% ggplot()+ geom_vline(aes(xintercept = narrative_time))+ facet_wrap(~word, ncol = 1) Скачайте все произведения Гертруды Стайн из базы данных, уберите стопслова и визуализируйте топ 20 слов из каждого текста. Скачайте произведение Гертруды Стайн “Geography and Plays” и визуализируйте распределение в тексте слов time и living. 5.4 Пакет stopwords Выше мы упомянули, что в пакет tidytext встроен список английских стопслов. Стопслова для других язков можно раздобыть списки для других языков, используя пакет stopwords. Вместо имени языка, функция принимает ISO код языыка: library(stopwords) stopwords(&quot;ru&quot;) [1] &quot;и&quot; &quot;в&quot; &quot;во&quot; &quot;не&quot; &quot;что&quot; &quot;он&quot; &quot;на&quot; [8] &quot;я&quot; &quot;с&quot; &quot;со&quot; &quot;как&quot; &quot;а&quot; &quot;то&quot; &quot;все&quot; [15] &quot;она&quot; &quot;так&quot; &quot;его&quot; &quot;но&quot; &quot;да&quot; &quot;ты&quot; &quot;к&quot; [22] &quot;у&quot; &quot;же&quot; &quot;вы&quot; &quot;за&quot; &quot;бы&quot; &quot;по&quot; &quot;только&quot; [29] &quot;ее&quot; &quot;мне&quot; &quot;было&quot; &quot;вот&quot; &quot;от&quot; &quot;меня&quot; &quot;еще&quot; [36] &quot;нет&quot; &quot;о&quot; &quot;из&quot; &quot;ему&quot; &quot;теперь&quot; &quot;когда&quot; &quot;даже&quot; [43] &quot;ну&quot; &quot;вдруг&quot; &quot;ли&quot; &quot;если&quot; &quot;уже&quot; &quot;или&quot; &quot;ни&quot; [50] &quot;быть&quot; &quot;был&quot; &quot;него&quot; &quot;до&quot; &quot;вас&quot; &quot;нибудь&quot; &quot;опять&quot; [57] &quot;уж&quot; &quot;вам&quot; &quot;сказал&quot; &quot;ведь&quot; &quot;там&quot; &quot;потом&quot; &quot;себя&quot; [64] &quot;ничего&quot; &quot;ей&quot; &quot;может&quot; &quot;они&quot; &quot;тут&quot; &quot;где&quot; &quot;есть&quot; [71] &quot;надо&quot; &quot;ней&quot; &quot;для&quot; &quot;мы&quot; &quot;тебя&quot; &quot;их&quot; &quot;чем&quot; [78] &quot;была&quot; &quot;сам&quot; &quot;чтоб&quot; &quot;без&quot; &quot;будто&quot; &quot;человек&quot; &quot;чего&quot; [85] &quot;раз&quot; &quot;тоже&quot; &quot;себе&quot; &quot;под&quot; &quot;жизнь&quot; &quot;будет&quot; &quot;ж&quot; [92] &quot;тогда&quot; &quot;кто&quot; &quot;этот&quot; &quot;говорил&quot; &quot;того&quot; &quot;потому&quot; &quot;этого&quot; [99] &quot;какой&quot; &quot;совсем&quot; &quot;ним&quot; &quot;здесь&quot; &quot;этом&quot; &quot;один&quot; &quot;почти&quot; [106] &quot;мой&quot; &quot;тем&quot; &quot;чтобы&quot; &quot;нее&quot; &quot;кажется&quot; &quot;сейчас&quot; &quot;были&quot; [113] &quot;куда&quot; &quot;зачем&quot; &quot;сказать&quot; &quot;всех&quot; &quot;никогда&quot; &quot;сегодня&quot; &quot;можно&quot; [120] &quot;при&quot; &quot;наконец&quot; &quot;два&quot; &quot;об&quot; &quot;другой&quot; &quot;хоть&quot; &quot;после&quot; [127] &quot;над&quot; &quot;больше&quot; &quot;тот&quot; &quot;через&quot; &quot;эти&quot; &quot;нас&quot; &quot;про&quot; [134] &quot;всего&quot; &quot;них&quot; &quot;какая&quot; &quot;много&quot; &quot;разве&quot; &quot;сказала&quot; &quot;три&quot; [141] &quot;эту&quot; &quot;моя&quot; &quot;впрочем&quot; &quot;хорошо&quot; &quot;свою&quot; &quot;этой&quot; &quot;перед&quot; [148] &quot;иногда&quot; &quot;лучше&quot; &quot;чуть&quot; &quot;том&quot; &quot;нельзя&quot; &quot;такой&quot; &quot;им&quot; [155] &quot;более&quot; &quot;всегда&quot; &quot;конечно&quot; &quot;всю&quot; &quot;между&quot; Пакет предоставляет несколько источников списков: stopwords_getsources() [1] &quot;snowball&quot; &quot;stopwords-iso&quot; &quot;misc&quot; &quot;smart&quot; [5] &quot;marimo&quot; &quot;ancient&quot; &quot;nltk&quot; &quot;perseus&quot; Давайте посмотрем какие языки сейчас доступны: map(stopwords_getsources(), stopwords_getlanguages) [[1]] [1] &quot;da&quot; &quot;de&quot; &quot;en&quot; &quot;es&quot; &quot;fi&quot; &quot;fr&quot; &quot;hu&quot; &quot;ir&quot; &quot;it&quot; &quot;nl&quot; &quot;no&quot; &quot;pt&quot; &quot;ro&quot; &quot;ru&quot; &quot;sv&quot; [[2]] [1] &quot;af&quot; &quot;ar&quot; &quot;hy&quot; &quot;eu&quot; &quot;bn&quot; &quot;br&quot; &quot;bg&quot; &quot;ca&quot; &quot;zh&quot; &quot;hr&quot; &quot;cs&quot; &quot;da&quot; &quot;nl&quot; &quot;en&quot; &quot;eo&quot; [16] &quot;et&quot; &quot;fi&quot; &quot;fr&quot; &quot;gl&quot; &quot;de&quot; &quot;el&quot; &quot;ha&quot; &quot;he&quot; &quot;hi&quot; &quot;hu&quot; &quot;id&quot; &quot;ga&quot; &quot;it&quot; &quot;ja&quot; &quot;ko&quot; [31] &quot;ku&quot; &quot;la&quot; &quot;lt&quot; &quot;lv&quot; &quot;ms&quot; &quot;mr&quot; &quot;no&quot; &quot;fa&quot; &quot;pl&quot; &quot;pt&quot; &quot;ro&quot; &quot;ru&quot; &quot;sk&quot; &quot;sl&quot; &quot;so&quot; [46] &quot;st&quot; &quot;es&quot; &quot;sw&quot; &quot;sv&quot; &quot;th&quot; &quot;tl&quot; &quot;tr&quot; &quot;uk&quot; &quot;ur&quot; &quot;vi&quot; &quot;yo&quot; &quot;zu&quot; [[3]] [1] &quot;ar&quot; &quot;ca&quot; &quot;el&quot; &quot;gu&quot; &quot;zh&quot; [[4]] [1] &quot;en&quot; [[5]] [1] &quot;en&quot; &quot;de&quot; &quot;ru&quot; &quot;ar&quot; &quot;he&quot; &quot;zh_tw&quot; &quot;zh_cn&quot; &quot;ko&quot; &quot;ja&quot; [[6]] [1] &quot;grc&quot; &quot;la&quot; [[7]] [1] &quot;ar&quot; &quot;az&quot; &quot;da&quot; &quot;nl&quot; &quot;en&quot; &quot;fi&quot; &quot;fr&quot; &quot;de&quot; &quot;el&quot; &quot;hu&quot; &quot;id&quot; &quot;it&quot; &quot;kk&quot; &quot;ne&quot; &quot;no&quot; [16] &quot;pt&quot; &quot;ro&quot; &quot;ru&quot; &quot;sl&quot; &quot;es&quot; &quot;sv&quot; &quot;tg&quot; &quot;tr&quot; [[8]] [1] &quot;grc&quot; &quot;la&quot; Мы видим, что есть несколько источников для русского языка: length(stopwords(&quot;ru&quot;, source = &quot;snowball&quot;)) [1] 159 length(stopwords(&quot;ru&quot;, source = &quot;stopwords-iso&quot;)) [1] 559 "],["работа-со-временем-lubridate.html", "6 Работа со временем: lubridate 6.1 Создание даты 6.2 Извлечение компонентов даты 6.3 Операции с датами 6.4 Визуализация времени: данные Левада-центра", " 6 Работа со временем: lubridate library(tidyverse) Мы обсуждали, что переменные бывают разные. О них, возможно, следует думать как о шкале: Кажется, что время – просто обычная числовая переменная, на которой определены все обычные операции сложения вычитания и т. п. Однако стоит держать в голове несколько фактов: Не каждый год содержит 365 дней. Существуют високосные года. Не каждый день содержит 24 часа. Во многих странах используют переход на летнее и зимнее время. Не в каждой минуте 60 секунд. Существуют дополнительная секунда, которую добавляют чтобы компенсировать замедление во вращении земли (тогда после секунды 23:59:59 идет секунда 23:59:60). Все это мелочи учтены в пакете lubridate, созданном для работы со временем в R (https://rawgit.com/rstudio/cheatsheets/master/lubridate.pdf, туториал доступен здесь и по команде vignette(\"lubridate\")). Первые команды, которые нужно изучить: library(lubridate) Attaching package: &#39;lubridate&#39; The following objects are masked from &#39;package:base&#39;: date, intersect, setdiff, union today() [1] &quot;2022-05-28&quot; now() [1] &quot;2022-05-28 17:50:04 MSK&quot; Как видно, из этих функций в R можно работать как с датами, так и с временем. В качестве иллюстрации мы будем использовать датасет flights из пакета nycflights13, в котором содержатся данные полетов из Нью Йорка в 2013 года. library(nycflights13) flights 6.1 Создание даты Самый простой способ получить дату — это преобразовать строку в формат даты, для этого надо просто упорядочить y (year), m (month) и d (day) в команде: ymd(&quot;2020-01-21&quot;) [1] &quot;2020-01-21&quot; ymd(&quot;20-01-21&quot;) [1] &quot;2020-01-21&quot; ymd(&quot;20.01.21&quot;) [1] &quot;2020-01-21&quot; ymd(&quot;20/01/21&quot;) [1] &quot;2020-01-21&quot; ymd(&quot;200121&quot;) [1] &quot;2020-01-21&quot; mdy(&quot;January 21st, 2020&quot;) [1] &quot;2020-01-21&quot; dmy(&quot;21-Jan-2020&quot;) [1] &quot;2020-01-21&quot; Команды понимают не только английский (хоть и с трудом): dmy(&quot;21 янв 2020&quot;, locale = &quot;ru_RU.UTF-8&quot;) [1] &quot;2020-01-21&quot; dmy(&quot;21 янв. 2020&quot;, locale = &quot;ru_RU.UTF-8&quot;) [1] &quot;2020-01-21&quot; dmy(&quot;21 ян 2020&quot;, locale = &quot;ru_RU.UTF-8&quot;) [1] NA dmy(&quot;21 янва 2020&quot;, locale = &quot;ru_RU.UTF-8&quot;) [1] &quot;2020-01-21&quot; dmy(&quot;21 января 2020&quot;, locale = &quot;ru_RU.UTF-8&quot;) [1] NA dmy(&quot;21 январь 2020&quot;, locale = &quot;ru_RU.UTF-8&quot;) [1] &quot;2020-01-21&quot; dmy(&quot;21 Январь 2020&quot;, locale = &quot;ru_RU.UTF-8&quot;) [1] &quot;2020-01-21&quot; Аналогично сделаны команды состоящие из h, m, s: hms(&quot;20:01:02&quot;) [1] &quot;20H 1M 2S&quot; hm(&quot;20.01&quot;) [1] &quot;20H 1M 0S&quot; ms(&quot;23:59&quot;) [1] &quot;23M 59S&quot; Также существует команда make_datetime(), которая позволяет сделать дату из нескольких переменных: flights %&gt;% mutate(departure = make_datetime(year, month, day, hour, minute)) %&gt;% select(departure) 6.2 Извлечение компонентов даты Для извлечения компонентов даты используются функции year(), month(), week() (номер недели в году), mday() (day of the month), wday() (номер дня в неделе), yday() (номер дня в году), hour(), minute() и second(): date_example &lt;- flights$time_hour[1] date_example [1] &quot;2013-01-01 05:00:00 EST&quot; year(date_example) [1] 2013 month(date_example) [1] 1 month(date_example, label = TRUE) [1] Jan 12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec month(date_example, label = TRUE, abbr = FALSE) [1] January 12 Levels: January &lt; February &lt; March &lt; April &lt; May &lt; June &lt; ... &lt; December month(date_example, label = TRUE, locale = &quot;ru_RU.UTF-8&quot;) [1] янв 12 Levels: янв &lt; фев &lt; мар &lt; апр &lt; мая &lt; июн &lt; июл &lt; авг &lt; сен &lt; ... &lt; дек week(date_example) [1] 1 mday(date_example) [1] 1 wday(date_example) [1] 3 wday(date_example, label = TRUE) [1] Tue Levels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat wday(date_example, label = TRUE, abbr = FALSE) [1] Tuesday 7 Levels: Sunday &lt; Monday &lt; Tuesday &lt; Wednesday &lt; Thursday &lt; ... &lt; Saturday wday(date_example, label = TRUE, locale = &quot;ru_RU.UTF-8&quot;) [1] Вт Levels: Вс &lt; Пн &lt; Вт &lt; Ср &lt; Чт &lt; Пт &lt; Сб yday(date_example) [1] 1 hour(date_example) [1] 5 minute(date_example) [1] 0 second(date_example) [1] 0 Так же есть функция leap_year(), которая сообщает информацию, является ли выбранный год високосным: leap_year(2019) [1] FALSE leap_year(2020) [1] TRUE Постройте график распределения полетов по дням недели из датасета flights пакета nycflights13. 6.3 Операции с датами Если взять две даты, то можно узнать разницу между ними и т. п.: ymd(&quot;2020-01-21&quot;) - ymd(&quot;2020-01-19&quot;) Time difference of 2 days ymd(&quot;2020-01-19&quot;) - ymd(&quot;2020-01-21&quot;) Time difference of -2 days Обратите внимание на результат работы этого выражения: hm(&quot;21:00&quot;) - hm(&quot;18:10&quot;) [1] &quot;3H -10M 0S&quot; Видимо, почему-то в таком использовании происходит поэлементная операция с часами, минутами, и секундами, так что в результате получаются отрицательные минуты. Однако, если использовать полные даты, то этого эффекта нет: ymd_hm(&quot;2020-01-21, 21:00&quot;) - ymd_hm(&quot;2020-01-21, 18:10&quot;) Time difference of 2.833333 hours ymd_hm(&quot;2020-01-21, 21:00&quot;) - hm(&quot;18:10&quot;) [1] &quot;2020-01-21 02:50:00 UTC&quot; Также существует функция difftime(), которая позволяет настраивать единицы, в которых выдается результат: difftime(ymd_hm(&quot;2020-01-21, 21:00&quot;), ymd_hm(&quot;2020-01-21, 18:10&quot;), units = &quot;mins&quot;) Time difference of 170 mins difftime(ymd_hm(&quot;2020-01-21, 21:00&quot;), ymd_hm(&quot;2020-01-21, 18:10&quot;), units = &quot;hours&quot;) Time difference of 2.833333 hours У меня есть шенгенская мультивиза на 90 дней. Я совершил несколько поездок в Европу и записал их в этот датасет. Определите, сколько дней я еще могу находиться в Евросоюзе? Однако простые даты, не являются временными отрезками, так что их нельзя складывать, вычитать, умножать и т. д. Для удобства операций в lubridate вводится несколько сущностей: periods — промежутки времени, которые игнорируют нерегулярности во времени, сразу прибавляя 1 к соответствующему разряду, вводятся функциями years(), months(), weeks(), days(), hours(), minutes(), seconds(), period() duration — промежутки времени, которые учитывают нерегулярности во времени, добавляя стандартную длительность единицы, вводятся функциями dyears(), dweeks(), ddays(), dhours(), dminutes(), dseconds(), duration() Рассмотрим несколько сложных случаев: високосный год ymd(&quot;2019-03-01&quot;)+years(1) [1] &quot;2020-03-01&quot; ymd(&quot;2019-03-01&quot;)+dyears(1) [1] &quot;2020-02-29 06:00:00 UTC&quot; переход на летнее время ymd_hms(&quot;2020-03-07 13:00:00&quot;, tz = &quot;America/New_York&quot;) + days(1) [1] &quot;2020-03-08 13:00:00 EDT&quot; ymd_hms(&quot;2020-03-07 13:00:00&quot;, tz = &quot;America/New_York&quot;) + ddays(1) [1] &quot;2020-03-08 14:00:00 EDT&quot; переход на зимнее время ymd_hms(&quot;2020-10-31 13:00:00&quot;, tz = &quot;America/New_York&quot;) + days(1) [1] &quot;2020-11-01 13:00:00 EST&quot; ymd_hms(&quot;2020-10-31 13:00:00&quot;, tz = &quot;America/New_York&quot;) + ddays(1) [1] &quot;2020-11-01 12:00:00 EST&quot; Последняя операция с датами, которую мы рассмотрим — округление: floor_date() — округление в меньшую сторону round_date() — математическое округление ceiling_date() — округление в большую сторону floor_date(ymd(&quot;2020-01-16&quot;), unit = &quot;month&quot;) [1] &quot;2020-01-01&quot; round_date(ymd(&quot;2020-01-16&quot;), unit = &quot;month&quot;) [1] &quot;2020-01-01&quot; round_date(ymd(&quot;2020-01-17&quot;), unit = &quot;month&quot;) [1] &quot;2020-01-01&quot; ceiling_date(ymd(&quot;2020-01-16&quot;), unit = &quot;month&quot;) [1] &quot;2020-02-01&quot; ceiling_date(ymd(&quot;2020-01-16&quot;), unit = &quot;year&quot;) [1] &quot;2021-01-01&quot; 6.4 Визуализация времени: данные Левада-центра Пакет tidyverse понимает переменные типа дата, и позволяет их фильтровать и визуализировать. Возьмем для примера датасет из проекта The Unwelcomed Мохамада А. Вэйкда (Mohamad A. Waked), содержащий информацию о месте и причинах смерти мигрантов и беженцев по всему миру с января 2014 года по июнь 2019 года. unwelcomed &lt;- read_csv(&quot;https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/death_of_migrants_and_refugees_from_the_Unwelcomed_project.csv&quot;) unwelcomed %&gt;% mutate(date = dmy(date)) %&gt;% ggplot(aes(date, total_death_missing, color = collapsed_cause))+ geom_point()+ scale_y_log10()+ labs(y = &quot;number of death/missing&quot;) unwelcomed %&gt;% mutate(date = dmy(date)) %&gt;% filter(date &lt; dmy(&quot;1-1-2016&quot;)) %&gt;% ggplot(aes(date, total_death_missing, color = collapsed_cause))+ geom_point()+ scale_y_log10()+ labs(y = &quot;number of death/missing&quot;) Однако ко переменным со врменем не всегда относятся аккуратно. Рассмотрим график с сайта Левада-центра — российской негосударственной исследовательской организации, которая проводит социологические и маркетинговые исследования (график взят отсюда): На первый взгляд, в этом графике нет ничего странного, однако если присмотреться к динамической версии на сайте Левада-центра, можно обнаружить, что на идущие подряд измерения расположены на одинаковом расстоянии друг от друга, например, 05.2014, 07.2014, 11.2014. Вот здесь можно скачать данные, по которым строился этот график. Вот как он выглядит, если считать временную переменную как время levada &lt;- read_csv(&quot;https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/2019.01_levada_countries.csv&quot;) levada %&gt;% mutate(date = str_c(&quot;1-&quot;, date), date = dmy(date)) %&gt;% filter(towards == &quot;USA&quot;) %&gt;% pivot_longer(names_to = &quot;answer&quot;, values_to = &quot;number&quot;, good:bad) %&gt;% ggplot(aes(date, number, color = answer))+ geom_line()+ labs(x = &quot;&quot;, y = &quot;&quot;, caption = &quot;данные Левада-центра&quot;)+ scale_y_continuous(limits = c(0, 100))+ theme(legend.position = c(0.1, 0.9), legend.title = element_blank()) На графике теперь видно, насколько регулярно проводились опросы: в начале 90-ых опросы проводились реже, потом часто, потом в районе 2010 года был перерыв. График Левада-центра можно оправдать тем, что они представляют данные от замера к замеру, так что по оси x находится как бы категориальная переменная со значениями замер 05.2014, замер 07.2014, замер 11.2014 и т. д. Однако это совсем неочевидно из графика. Используя весь датасет Левада-центра, постройте следующий график. "],["работа-с-геоданными-leaflet.html", "7 Работа с геоданными: leaflet 7.1 Векторная и растровая графика 7.2 Картографические примитивы 7.3 leaflet", " 7 Работа с геоданными: leaflet library(&quot;tidyverse&quot;) 7.1 Векторная и растровая графика Перед тем как обсуждать карты, следует сначала обсудить разницу между векторной и растровой графикой. Растровые изображения представляют собой набор упорядоченных пикселей, про каждый из которых храниться информация о цвете. Векторное изображение нельзя бесконечно увеличивать — в какой-то момент станут видны пиксели, которые в каком-то смысле являются пределом увелечения. Наиболее популярные форматы растровых изображений: JPEG, GIF, PNG, BMP, TIFF и другие. В векторных изображениях инормация храниться как собрани точек, линий и полигонов в некоторой системе координат, что позволяет бесконечно увеличивать такие изображения не теряя в качестве. Наиболее популярные форматы векторных изображений: PDF, SVG, EPS и другие. Современные технологии позволяют соединять растровые и векторные изображения, а также трансформировать их друг в друга. Картографические данные могут попадать в разные типы: точки (столицы всех стран), линии (улицы в каком-нибудь городе), полигоны (границы стран и меньших регионов) обычно имеют некоторую геопривязку (для простоты давайте считать такими, все, что имеет широту и долготу), так что могут быть представлены векторно, однако существует достаточно много информации, которую невозможно представить никак подругому, кроме как векторно: спутниковые снимки, существующие физические/политические/климатические/исторические и т. п. карты, выдача картографических сервисов, таких как Google Maps. Кроме того, занимаясь любыми типами визуализации следует помнить о разнице статической визаулизации, которую после создания нельзя изменить, и динамической визуализации, которая позволяет пользователям изменять себя (увеличиваться и уменьшаться, кликать на собрание точек и видеть их значения и т. п.). В данной главе, в отличие от предыдущих мы сосредоточимся на пакете для динамичского картографирования leaflet. Достаточно много тем останется за пределами этой главы: изменение проекции, манипуляции с географическими данными, работа с растровыми изображениями и другие (см., например, (Lovelace, Nowosad, and Muenchow 2019), доступная здесь). 7.2 Картографические примитивы В картографии существуют свои элементарные единицы: Эти единицы поддерживают популярные пакеты для манипуляции с георграфическими объектами: sp, sf и другие. В данном разделе мы не будем учиться операциям с этими объектами (объединение, вычитание и т. п., подробности смотрите в документации к пакету sp или в уже упомянавшейся книжке (Lovelace, Nowosad, and Muenchow 2019)). 7.3 leaflet Для начала включим библиотеку: library(&quot;leaflet&quot;) Здесь доступен cheatsheet, посвященный пакету leaflet. 7.3.1 .csv файлы Источником географических данных могут быть обычные привычные нам csv файлы. Например, вот здесь, хранится датасет из проекта The Unwelcomed Мохамада А. Вэйкда (Mohamad A. Waked), содержащий информацию о месте и причинах смерти мигрантов и беженцев по всему миру с января 2014 года по июнь 2019 года. unwelcomed &lt;- read_csv(&quot;https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/death_of_migrants_and_refugees_from_the_Unwelcomed_project.csv&quot;) id — идентификационный номер; date — дата происшедшего; total_death_missing — количество погибших/пропавших; location — место происшедшего; lat — широта; lon — долгота; collapsed_region — обобщенная информация о регионе; region — информация о регионе; collapsed_cause — обобщенная информация о причине смерти; cause_of_death — информация о причине смерти. Информация о широте и долготе иногда записывают в градусах, минутах и секундах, а иногда в десятичной записи, в R обычно используется десятичная запись. В интернете легко найти конвертеры из одного формата в другой и обратно. Самый простой способ нанести на карту координаты, это использовать комбинацию функций leaflet() %&gt;% addCircles(): unwelcomed %&gt;% leaflet() %&gt;% addCircles(lng = ~lon, # обратите внимание на особый синтаксис с тильдой lat = ~lat) Чтобы точки не “висели в воздухе” можно добавить подложку: unwelcomed %&gt;% leaflet() %&gt;% addTiles() %&gt;% addCircles(lng = ~lon, lat = ~lat) Функция addCircles() имеет массу аргументов, которая отвечает за отображение: radius color opacity fill fillColor label popup К сожалению, в пакете leaflet нет такого удобного автоматического раскрашивания по некоторой переменной, поэтому для решения такой задачи нужно сначала создать свою функцию раскрашивания. Это делается при помощи функций colorNumeric(), colorFactor(), colorBin() или colorQuantile(). pal_cat &lt;- colorFactor(&quot;Set3&quot;, domain = unwelcomed$collapsed_cause) pal_cat(unwelcomed$collapsed_cause[1]) [1] &quot;#D9D9D9&quot; Теперь в переменную pal_cat записана функция, которая возварщает цвета в зависимости от значения. В качестве первого аргумента в фукнций colorNumeric(), colorFactor(), colorBin() или colorQuantile() отправляется палитра, которую пользователь может задать сам или использовать уже имеющуюся (их можно посмотреть при помощи команды RColorBrewer::display.brewer.all()): RColorBrewer::display.brewer.all() Теперь мы готовы сделать нашу первую осмысленную карту unwelcomed %&gt;% filter(str_detect(date, &quot;2014&quot;)) %&gt;% leaflet() %&gt;% addTiles() %&gt;% addCircles(lng = ~lon, lat = ~lat, label = ~total_death_missing, # пусть возникает подпись с количеством color = ~pal_cat(collapsed_cause), # это обобщенная причина opacity = 0.9, popup = ~cause_of_death) %&gt;% # а это конкретная причина, появляется при клике мышкой addLegend(pal = pal_cat, values = ~collapsed_cause, title = &quot;&quot;) Вообще цветовая схема не очень сочетается с подложкой, так что можно поменять подложку при помощи функции addProviderTiles() (галлерею подложек можно посмотреть вот здесь): unwelcomed %&gt;% filter(str_detect(date, &quot;2014&quot;)) %&gt;% leaflet() %&gt;% addProviderTiles(&quot;Stamen.TonerLite&quot;) %&gt;% addCircles(lng = ~lon, lat = ~lat, label = ~total_death_missing, # пусть возникает подпись с количеством color = ~pal_cat(collapsed_cause), # это обобщенная причина opacity = 0.9, popup = ~cause_of_death) %&gt;% # а это конкретная причина, появляется при клике мышкой addLegend(pal = pal_cat, values = ~collapsed_cause, title = &quot;&quot;) Существует проект Карта ДТП, в котором собран датасет c дорожными происшествиями в России за некоторый временной промежуток. Визуализируйте все столкновения из датасета. Что можно увидеть на получившейся карте? 📋 список подсказок ➡ 👁 Все забыто… Как скачать датасет? ➡ Надо использовать функцию read_csv() из пакета tidyverse. 👁 Карта получилась, но есть какие-то точки на Чукотке, которые не стой стороны… ➡ Да, это стандартная проблема с Чукоткой. Прибавьте к значениям долготы 360. 👁 А как исправить значения на Чукотке? ➡ Ну нужно использовать функцию mutate(), а в ней ifelse(). Если значения меньше нуля — прибавляем 360, если больше — оставляем как есть. 7.3.2 Комбинация карт: leafsync Карты, как и все объекты в R тоже можно записать в переменную: unwelcomed %&gt;% filter(str_detect(date, &quot;2014&quot;)) %&gt;% leaflet() %&gt;% addProviderTiles(&quot;Stamen.TonerLite&quot;) %&gt;% addCircles(lng = ~lon, lat = ~lat, label = ~total_death_missing, # пусть возникает подпись с количеством color = ~pal_cat(collapsed_cause), # это обобщенная причина opacity = 0.9, popup = ~cause_of_death) %&gt;% # а это конкретная причина, появляется при клике мышкой addLegend(pal = pal_cat, values = ~collapsed_cause, title = &quot;2014&quot;) -&gt; m_2014 Теперь если вызвать переменную m_2014, появится карта, которую мы сделали. Но, что если мы хотим отобразить рядом карты 2014 года и 2015 года? Как сделать фасетизацию? К сожалению, функции для фасетизации в пакете не предусмотрена, но мы можем сделать ее самостоятельно. Для начала создадим вторую карту: unwelcomed %&gt;% filter(str_detect(date, &quot;2015&quot;)) %&gt;% leaflet() %&gt;% addProviderTiles(&quot;Stamen.TonerLite&quot;) %&gt;% addCircles(lng = ~lon, lat = ~lat, label = ~total_death_missing, # пусть возникает подпись с количеством color = ~pal_cat(collapsed_cause), # это обобщенная причина opacity = 0.9, popup = ~cause_of_death) %&gt;% # а это конкретная причина, появляется при клике мышкой addLegend(pal = pal_cat, values = ~collapsed_cause, title = &quot;2015&quot;) -&gt; m_2015 Включим библиотеку: library(&quot;leafsync&quot;) И теперь соединим две карты воедино: sync(m_2014, m_2015) 7.3.3 Работа с .geojson В данном разделе мы будем анализировать датасет, содержащий данные по всем странам мира. countries &lt;- jsonlite::read_json(&quot;https://github.com/agricolamz/DS_for_DH/raw/master/data/countries.geojson&quot;) Обратите внимание, как уже говорилось в разделе @ref{lists}, так как jsonlite конфликтует с одной из функций из tidyverse, я не загружаю библиотеку полностью при помощи команды library(jsonlite), а обращаюсь к функциям пакета при помощи выражения jsonlite::...(). В загруженном датасете достаточно много переменных, мы попробуем проанализировать количество населения и уровень доходов. countries$features %&gt;% map(&quot;properties&quot;) %&gt;% tibble(name = map_chr(., &quot;name&quot;), pop_est = map_chr(., &quot;pop_est&quot;), income = map_chr(., &quot;income_grp&quot;)) %&gt;% select(-1) %&gt;% mutate(pop_est = as.double(pop_est), income = as.factor(income)) -&gt; country_features country_features Еще одно преимущество формата .geojson заключается в том, что его позволяет просматривать github (см. пример). Самый простой способ визуализировать .geojson это используя функцию addGeoJSON(), которая в качестве аргумента принимает .geojson файл. leaflet() %&gt;% addGeoJSON(geojson = countries) Проблема этого подхода заключается в том, что файл .geojson содержит в себе форматирование, поэтому если пользователь хочет поменять отображение объектов, необходимо добавить список style к каждому узлу. Во-первых, нужно добавить список style в корень файла .geojson. В результате, это изменит отображение всех списков: countries$style = list( weight = 1, color = &quot;#555555&quot;, opacity = 1, fillOpacity = 0.8) leaflet() %&gt;% addGeoJSON(geojson = countries) Во-вторых, следует создать палитры для раскрашивания. Это делается при помощи функций colorNumeric(), colorFactor(), colorBin() или colorQuantile(). pal_num &lt;- colorNumeric(&quot;Greens&quot;, domain = c(min(country_features$pop_est), max(country_features$pop_est))) pal_cat &lt;- colorFactor(&quot;RdYlBu&quot;, domain = country_features$income) Созданные переменные pal_num() и pal_cat() сами являются функциями и возвращают раскраску в зависимости от значения: pal_num(country_features$pop_est[1]) [1] &quot;#F7FCF5&quot; pal_cat(country_features$income[1]) [1] &quot;#FDAE61&quot; В-третьих, нужно создать векторы с новыми цветами: country_features %&gt;% mutate(pop_est_color = pal_num(pop_est), income_color = pal_cat(income)) -&gt; country_features country_features В-четвертых, нужно присвоить каждому узлу свой список style: map(seq_along(countries$features), function(x){ countries$features[[x]]$properties$style &lt;- list(fillColor = country_features$income_color[x]) countries$features[[x]] }) -&gt; countries$features И последний, пятый шаг, это нарисовать получивший .geojson: leaflet() %&gt;% addGeoJSON(geojson = countries) %&gt;% addLegend(pal = pal_cat, values = country_features$income, title = &quot;Income&quot;) Повторите шаги 4 и 5 для числовой переменной (количество населения) из датасета. Вот cheatsheet по теории вероятности. Ссылки на литературу "],["описательная-статистика-распределения.html", "8 Описательная статистика, распределения 8.1 Описательная статистика 8.2 От частотности к вероятности", " 8 Описательная статистика, распределения library(tidyverse) Мы обсуждали разные типы переменных: В данном занятии мы сосредоточимся на категориальных и числовых переменных. 8.1 Описательная статистика Описательная статистика — это общий термин, в который включают понятия позволяющие оценить тренд в данных. 8.1.1 Категориальные переменные Для категориальных переменных описательных статистик не так много: количество частоты энтропия Возьмем для примера датасет starwars. Мы легко можем посчитать количество существо разных расс: starwars %&gt;% count(species, sort = TRUE) Мы также легко можем посчитать долю существо разных расс: starwars %&gt;% count(species, sort = TRUE) %&gt;% mutate(ratio = n/sum(n)) Долю легко перевести в проценты: starwars %&gt;% count(species, sort = TRUE) %&gt;% mutate(ratio = n/sum(n)*100) Мы также легко можем посчитать энтропию. В том виде, как ее сформулировал Клод Шеннон, формула выглядит так: \\[H = -\\sum_{i=1}^n p_i\\times\\log_2(p_i),\\ где\\] \\(H\\) — энтропия \\(p_i\\) — доля \\(i\\)-того независимого исхода из всех независимых исходов starwars %&gt;% count(species, sort = TRUE) %&gt;% mutate(ratio = n/sum(n)) %&gt;% summarise(entropy = -sum(ratio*log2(ratio))) Что показывает эта мера? Рассмотрим следующий тиббл: tibble(x = c(&quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;, &quot;a&quot;), group = rep(c(&quot;first&quot;, &quot;second&quot;, &quot;third&quot;), each = 6), id = rep(1:6, 3)) %&gt;% pivot_wider(names_from = group, values_from = x) Давайте посчитаем энтропию для каждой группы: tibble(x = c(&quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;, &quot;a&quot;), group = rep(c(&quot;first&quot;, &quot;second&quot;, &quot;third&quot;), each = 6)) %&gt;% count(group, x, sort = TRUE) %&gt;% group_by(group) %&gt;% mutate(ratio = n/sum(n)) %&gt;% summarise(entropy = -sum(ratio*log2(ratio))) Как видно, чем более разнообразна группа, тем выше энтропия. Посмотрим еще на такой тибл: tibble(x = c(&quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;с&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;с&quot;, &quot;a&quot;), group = rep(c(&quot;first&quot;, &quot;second&quot;, &quot;third&quot;), each = 6), id = rep(1:6, 3)) %&gt;% pivot_wider(names_from = group, values_from = x) tibble(x = c(&quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;с&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;с&quot;, &quot;a&quot;), group = rep(c(&quot;first&quot;, &quot;second&quot;, &quot;third&quot;), each = 6)) %&gt;% count(group, x, sort = TRUE) %&gt;% group_by(group) %&gt;% mutate(ratio = n/sum(n)) %&gt;% summarise(entropy = -sum(ratio*log2(ratio))) Как видно, чем “однороднее” группы, тем выше энтропия. Влияет ли порядок следования элементов в векторе на значение энтропии? да нет Посчитайте значение энтропии для переменных clarity, color и cut из датасета diamonds. У какой переменной значение энтропии наибольшее? clarity color cut 8.1.2 Числовые переменные Для числовых значений описательные статистики в целом предсказуемые: diamonds %&gt;% summarise(mean = mean(price), median = median(price), quantile_0.5 = quantile(price, 0.5), # квантиль quantile_0.25 = quantile(price, 0.25), quantile_0.1 = quantile(price, 0.1), min = min(price), max = max(price), var = var(price), # дисперсия sd = sd(price)) # cреднеквадратическое отклонение Смещенная оценка дисперсии выборки \\(X = {x_1, x_2, ..., x_n}\\): \\[\\sigma^2 = \\frac{1}{n}\\sum_{i = 1}^n(x_i - \\mu)^2,\\ где\\] \\(x_i\\) — i-тый элемент выборки X \\(\\mu\\) — среднее Несмещенная оценка дисперсии выборки \\(X = {x_1, x_2, ..., x_n}\\): \\[\\sigma^2 = \\frac{1}{n-1}\\sum_{i = 1}^n(x_i - \\mu)^2\\] Вот ссылка на видео, в котором объясняется, почему первая оценка смещенная. 8.2 От частотности к вероятности 8.2.1 Категориальная переменная Возьмем какой-нибудь простой случай двух взаимоисключающих исходов. Какая доля имен героев из датасета starwars начинается на букву B? Ответ округлите до 3 знаков после запятой. Мы получили такой результат на основании 9 успехов из 87 наблюдений. Но, что если они там еще чего-то наснимают? Какова вероятность, что в новом фильме будет герой на “B”, если предположить, что создатели стараются держать равновесие? 0.103? Но если там будет 13 новых героев, то полученная нами доля не будет иметь смысла, ведь 13*0.103 = 1.339. Для ответа на такие вопросы обычно используют биномиальное распределение. \\[P(k | n, p) = \\frac{n!}{k!(n-k)!} \\times p^k \\times (1-p)^{n-k} = {n \\choose k} \\times p^k \\times (1-p)^{n-k}\\] \\[ 0 \\leq p \\leq 1; n, k &gt; 0,\\ где\\] n — общее число наблюдений k — число успехов p — предполагаемая исследователем вероятность успеха Таким образом, если мы считаем вероятность 0.103 верной для данного процесса, то тогда вероятность не увидеть новых героев на букву “B” вероятнее, чем увидеть 3 или 5: Теперь мы сделали шаг в сторону вероятностной модели: все что нужно знать, что случаи двух взаимоисключающих исходов следует моделировать при помощи биномиального распределения. 8.2.2 Числовая переменная С числовой переменной все устроено похожим образом: дотплот, гистограмма, функция плотности. starwars %&gt;% ggplot(aes(height))+ geom_dotplot(method=&quot;histodot&quot;) Bin width defaults to 1/30 of the range of the data. Pick better value with `binwidth`. starwars %&gt;% ggplot(aes(height))+ geom_histogram(alpha = 0.5)+ geom_dotplot(method=&quot;histodot&quot;) `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Bin width defaults to 1/30 of the range of the data. Pick better value with `binwidth`. starwars %&gt;% ggplot(aes(height))+ geom_histogram(alpha = 0.5, binwidth = 20)+ geom_dotplot(method=&quot;histodot&quot;) Bin width defaults to 1/30 of the range of the data. Pick better value with `binwidth`. starwars %&gt;% ggplot(aes(height))+ geom_histogram(alpha = 0.5, binwidth = 30)+ geom_dotplot(method=&quot;histodot&quot;) Bin width defaults to 1/30 of the range of the data. Pick better value with `binwidth`. starwars %&gt;% ggplot(aes(height, y =..density..))+ geom_histogram(alpha = 0.5, binwidth = 30)+ geom_density() Мы можем предположить, что генеральная совокупность можно описать нормальным распределением. \\[P(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\times e^{-\\frac{\\left(x-\\mu\\right)^2}{2\\sigma^2}}\\] \\[\\mu \\in \\mathbb{R}; \\sigma^2 &gt; 0,\\ где\\] \\(\\mu\\) — среднее \\(\\sigma^2\\) — среднеквадратическое отклонение 8.2.3 Распределения В R встроено какое-то количество известных распределений. Все они представлены четырьмя функциями: d... (функция плотности, probability density function), p... (функция распределения, cumulative distribution function) — [интеграл площади под кривой или сумма всех значений] от начала до указанной квантили q... (обратная функции распределения, inverse cumulative distribution function) — значение p-той квантили распределения и r... (рандомные числа из заданного распределения). Рассмотрим все это на примере нормального распределения. tibble(x = 1:100, PDF = dnorm(x = x, mean = 50, sd = 10)) %&gt;% ggplot(aes(x, PDF))+ geom_point()+ labs(title = &quot;PDF нормального распределения (μ = 50, σ = 10)&quot;) tibble(x = 1:100, CDF = pnorm(x, mean = 50, sd = 10)) %&gt;% ggplot(aes(x, CDF))+ geom_point()+ labs(title = &quot;CDF нормального распределения (μ = 50, σ = 10)&quot;) tibble(quantiles = seq(0, 1, by = 0.01), value = qnorm(quantiles, mean = 50, sd = 10)) %&gt;% ggplot(aes(quantiles, value))+ geom_point()+ labs(title = &quot;inverse CDF нормального распределения (μ = 50, σ = 10)&quot;) tibble(sample = rnorm(100, mean = 50, sd = 10)) %&gt;% ggplot(aes(sample))+ geom_histogram()+ labs(title = &quot;выборка нормально распределенных чисел (μ = 50, σ = 10)&quot;) Если не использовать set.seed(), то результат работы рандомизатора нельзя будет повторить. Аналогично можно использовать функции dbinom(), pbinom(), qbinom() и rbinom() для биномиального распределения, а также ..t() для распределения Стьюдента, ...chisq() для распределения хи-квадрат и т. п. Биномиальное и нормальное распределения не единственные распределения, которые придумали люди: вот ресурс, на котором сделана попытка собрать все распределения и визуализировать связи между ними; вот приложение, позволяющие исследовать разные распределения. Рассмотрим задачу, которую обсуждали выше с именами героев из датасета strawars. Посчитайте значение функции плотности в точке 3 для биномиального распределения с вероятностью успеха 0.103. (округление до 3 знаков после запятой). 8.2.4 Давайте посчитаем вероятности Какова вероятность, что мы в новом фильме будет 3 и более новых героев на “B”? Это можно вычислить при помощи функции dbinom(), pbinom(): sum(dbinom(3:13, size = 13, prob = 0.103)) [1] 0.1429756 1-pbinom(2, size = 13, prob = 0.103) [1] 0.1429756 Если предположить, что рост героев Звездных войн постоянен и описывается нормальным распределением со средним 174 и стандартным откланением 30, какова вероятность что в новом фильме встретиться герой ростом между 200 и 230? `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. integrate(function(x){dnorm(x, mean = 174, sd = 30)}, lower = 200, upper = 230) 0.1620883 with absolute error &lt; 1.8e-15 pnorm(230, mean = 174, sd = 30) - pnorm(200, mean = 174, sd = 30) [1] 0.1620883 "],["проверка-статистических-гипотез.html", "9 Проверка статистических гипотез 9.1 О статистике 9.2 Проверка нулевой гипотезы 9.3 Классификация статистических тестов 9.4 Одновыборочные тесты 9.5 Двухвыборочные тесты 9.6 Послесловие 9.7 Рассказы Чехова и Зощенко 9.8 Obamacare", " 9 Проверка статистических гипотез 9.1 О статистике Статистика позволяет оценить какие-то стохастические процессы, которые происходят в мире. Центральное понятие статистики — генеральная совокупность, множество всех элементов какой-либо группы, параметр которой мы хотим оценить: все жители РФ при оценке роста; все возможные тексты писателя (реальные и потенциальные) при оценке частоты встречаемости каких-либо элементов; все возможные курсы валют при попытке оценить курс валюты завтра; все страны при попытке оценить количество уникальных имен в странах мира и т. д. Весь статистический анализ строится на основе предположений о свойствах генеральной совокупности и некоторой выборки из генеральной совкупности. Так если мы не можем взять всю генеральную совокупность и оценить ее параметр θ (средний рост, доля встречаемости гласных в текстах писателя и т. д.), то мы берем случайную выборку из генеральной совокупности и оцениваем параметр выборки θ̂ и делаем предположения о том, как параметр может быть устроен в генеральной совокупности. Если выборка, которой мы располагаем содержит в себе генеральную совокупность, то нужда оценить некоторый параметр казалось бы отпадает (в таком случае задача переходит в область теории вероятностей): Какая доля слов “не” в корпусе текстов Пушкина? Однако бывают задачи, которые даже обладая генеральной совокупностью, можно переформулировать в статистические: Какая доля слов “не” будет в свежеобнаруженном тексте Пушкина длины \\(n\\)? Исследователь каждый год ездит на остров Суматра и обнаруживает каждый год несколько неизвестных науке видов ящериц. С каждый годом он обнаруживает неизвестные науке виды ящериц все реже и реже. Можем ли мы оценить сколько ящериц неизвестного вида исследователь найдет в этом году? Существует несколько школ статистического анализа: фриквентистская и байесовская. Мы будем работать в рамках фриквентистской. 9.2 Проверка нулевой гипотезы Теперь мы обсудим стандартный трюк, который получил большую популярность в XX веке, и сейчас повсеместно продолжает использоваться. Этот трюк, к сожалению, помогает лишь показать, что что-то отличается, так что мы немножко переиначим наши задачи. Представим себе, что я исследую героев Звездных войн. Я верю, что герои с именем на “B” встречаются в Звездных войнах с вероятностью 0.103. В новом фильме из 13 новых персонажей 4 имеют имя на “B”, т. е. мы наблюдаем долю 0.31. Является ли разница межда наблюдениями 0.31 и ожиданиями 0.103 статистически значимой? Создадим две гипотезы: \\(H_0\\) — (нулевая гипотеза) разница не является статистически значимой, т. е. наблюдаемые данные могут происходят из ожидаемого распределения. \\(H_1\\) — (альтернативная гипотеза) разница является статистически значимой, т. е. наблюдаемые данные не могут происходят из ожидаемого распределения. Нулевая гипотеза — это гипотеза, которую каждый исследователь хочет отвергнуть, и принять альтернативную. После применения статистического критерия (каждый критерий зависит от конкретного статистического теста, а выбор теста зависит от типа данных) исследователь считает вероятность наблюдать такой или более экстремальный результат, если верна нулевая гипотеза (p-value, p-уровень значимости): sum(dbinom(4:13, size = 13, prob = 0.103)) [1] 0.03758494 Это же можно сделать при помощи следующей функции: binom.test(x = 4, n = 13, p = 0.103, alternative = &quot;greater&quot;) Exact binomial test data: 4 and 13 number of successes = 4, number of trials = 13, p-value = 0.03758 alternative hypothesis: true probability of success is greater than 0.103 95 percent confidence interval: 0.1126658 1.0000000 sample estimates: probability of success 0.3076923 Дальше в разных науках принимают некоторое критическое значение (в большинстве случаев это 0.05), и если p-value меньше данного заветного значения, считается, что тогда разница является статистически значимой. If all else fails, use “significant at a p&gt;0.05 level” and hope no one notices (https://xkcd.com/1478/) 9.3 Классификация статистических тестов 9.3.1 Количество выборок Одновыборочные тесты (one-sample tests) Двухвыборочные тесты (two-sample tests) многовыборочные тесты (multiple-sample tests) 9.3.2 Направление односторонние двусторонние 9.3.3 Парные vs. непарные непарные — если наблюдения в одной группе независимы друг от друга (мужчины vs. женщины, пожилые vs. молодые? и т. д.) парные — если наблюдения имеют соответствия между собой (настроение до пары R и после, измерение температуры обычным и инфракрасным термометром, и т. п.) 9.3.4 Параметрические vs. непараметрические Некоторые тесты работают с предположениями об устройстве данных. В нашем случае данные предположения: нормальность распределения. 9.3.5 Классификация тестов распределение тип группы # групп тест категориальные с заданным значением 1 биномиальный тест, χ² категориальные независимые 2 χ², тест Фишера, G-test (LL-score) категориальные зависимые 2 критерий Мак-Нимара нормальное с заданным значением 1 одновыборочный t-test нормальное независимые 2 t-test для независимых выборок нормальное зависимые 2 парный t-test не нормальное с заданным значением 1 критерий Уилкоксона не нормальное независимые 2 критерий Манна-Уитни не нормальное зависимые 2 критерий Уилкоксона 9.4 Одновыборочные тесты 9.4.1 Биномиальный тест Мы уже обсудили биномиальный тест выше. В частотном словаре [Ляшевская Шаров 2009], созданном на базе корпуса объемом 92 млн. словоупотреблений, существительное кенгуру имеет абсолютную частотность 0.0000021, а предлог к — 0.005389 (его вариант ко в расчет не берется). В некотором тексте длиной 61981 слов существительное кенгуру встречается 58 раз, а предлог к — 254. Можем ли мы считать, что это обычный ничем не примечательный результат? # кенгуру binom.test(x = 58, n = 61981, p = 0.0000021) Exact binomial test data: 58 and 61981 number of successes = 58, number of trials = 61981, p-value &lt; 2.2e-16 alternative hypothesis: true probability of success is not equal to 2.1e-06 95 percent confidence interval: 0.0007106442 0.0012095348 sample estimates: probability of success 0.0009357706 # к binom.test(x = 254, n = 61981, p = 0.005389) Exact binomial test data: 254 and 61981 number of successes = 254, number of trials = 61981, p-value = 5.862e-06 alternative hypothesis: true probability of success is not equal to 0.005389 95 percent confidence interval: 0.003610363 0.004632987 sample estimates: probability of success 0.00409803 Мы посчитали количество букв а в рассказе А. П. Чехова и получили 58 букв из рассказа длинной 699 букв (пробелы и латинские буквы выкинуты). Является ли этот результат неожиданным, если мы ожидали долю 0.08. Приведите значение p-value с точностью до 2 знаком после запятой. 9.4.2 Одновыборочный t-тест Из статьи С. Степановой 2011 мы знаем, что носители русского языка в среднем говорят 5.31 слога в секунду со стандартным отклонением 1,93 (мужчины 5.46 слога в секунду со средним отклонением 2.02, женщины 5.23 слога в секунду со средним отклонением 1.84, дети 3.86 слога в секунду со средним отклонением 1.67). Мы опросили 30 носителей деревни N и выяснили, что средняя равна 7, а стандартное отклонение равно 2. Является ли данная разницастатистически значимой? set.seed(42) data &lt;- rnorm(n = 30, mean = 7, sd = 2) tibble(data) %&gt;% ggplot(aes(data))+ geom_dotplot()+ geom_vline(xintercept = mean(data), size = 2, linetype = 2)+ geom_vline(xintercept = 5.31, size = 2, linetype = 2, color = &quot;red&quot;)+ annotate(geom = &quot;text&quot;, x = 3, color = &quot;red&quot;, y = 0.75, label = &quot;среднее согласно\\n[Степанова 2011]&quot;, size = 5) t.test(data, mu = 5.31) One Sample t-test data: data t = 3.9871, df = 29, p-value = 0.0004143 alternative hypothesis: true mean is not equal to 5.31 95 percent confidence interval: 6.199903 8.074444 sample estimates: mean of x 7.137174 Создайте 30 нормально распределенных наблюдений со средним 6 и стандартным отклонением 2, используя set.seed(42) и сравните полученные данные с результатами Степановой. Является ли разница статистически значимой? Приведите значение p-value с точностью до 2 знаком после запятой. t-тест имеет несколько предположений относительно структуры данных: нормальность распределения данных гомоскедостичность (гомогенность) дисперсии 9.4.3 Тест Уилкоксона Если данные не нормально распределено, обычно используют критерий Уилкоксона set.seed(42) data &lt;- rlnorm(n = 30, mean = 1.8, sd = 0.1) tibble(data) %&gt;% ggplot(aes(data))+ geom_dotplot()+ geom_vline(xintercept = mean(data), size = 2, linetype = 2)+ geom_vline(xintercept = 5.31, size = 2, linetype = 2, color = &quot;red&quot;)+ annotate(geom = &quot;text&quot;, x = 4.9, color = &quot;red&quot;, y = 0.75, label = &quot;среднее согласно\\n[Степанова 2011]&quot;, size = 5) wilcox.test(data, mu = 5.31) Wilcoxon signed rank exact test data: data V = 436, p-value = 3.239e-06 alternative hypothesis: true location is not equal to 5.31 9.5 Двухвыборочные тесты 9.5.1 Двухвыборочный t-тест Логика двухвыборочного теста такая же как одновыборочного: set.seed(42) sample_1 &lt;- rnorm(25, mean = 40, sd = 5) sample_2 &lt;- rnorm(25, mean = 50, sd = 4.5) tibble(sample_1, sample_2) %&gt;% pivot_longer(names_to = &quot;dataset&quot;, values_to = &quot;values&quot;, sample_1:sample_2) %&gt;% group_by(dataset) %&gt;% mutate(mean = mean(values)) %&gt;% ggplot(aes(values, fill = dataset))+ geom_dotplot(show.legend = FALSE)+ geom_vline(aes(xintercept = mean, color = dataset), size = 2, linetype = 2, show.legend = FALSE) t.test(sample_1, sample_2) Welch Two Sample t-test data: sample_1 and sample_2 t = -5.0632, df = 41.295, p-value = 9.005e-06 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: -11.046695 -4.748026 sample estimates: mean of x mean of y 40.93768 48.83504 В работе (Coretta 2017, https://goo.gl/NrfgJm) рассматривается отношения между длительностью гласного и придыхание согласного. Автор собрал данные 5 носителей исландского. Дальше он извлек длительность гласного, после которого были придыхательные и непридыхательные. Скачайте данные и Проверьте, правда ли, что гласные перед аспирированныем согласными статистикали значимо короче гласных после которых непридыхательные для носителя. В ответе приведите t-статистику c точностью до трех знаков после запятой. 9.5.2 Двухвыборочный парный t-тест set.seed(42) sample_1 &lt;- rnorm(25, mean = 40, sd = 5) sample_2 &lt;- sample_1 - rnorm(25, mean = 5) tibble(sample_1, sample_2) %&gt;% pivot_longer(names_to = &quot;dataset&quot;, values_to = &quot;values&quot;, sample_1:sample_2) %&gt;% group_by(dataset) %&gt;% mutate(mean = mean(values)) %&gt;% ggplot(aes(values, fill = dataset))+ geom_dotplot(show.legend = FALSE)+ geom_vline(aes(xintercept = mean, color = dataset), size = 2, linetype = 2, show.legend = FALSE) t.test(sample_1, sample_2, paired = TRUE) Paired t-test data: sample_1 and sample_2 t = 25.034, df = 24, p-value &lt; 2.2e-16 alternative hypothesis: true mean difference is not equal to 0 95 percent confidence interval: 4.350251 5.131990 sample estimates: mean difference 4.74112 9.5.3 Критерий Манна-Уитни Если данные не распределены нормально, тогда используется критерий Манна-Уитни (по английски его тоже называют Wilcoxon test). set.seed(42) data_1 &lt;- rlnorm(n = 30, mean = 1.8, sd = 0.1) data_2 &lt;- rlnorm(n = 30, mean = 1.6, sd = 0.1) tibble(data_1, data_2) %&gt;% pivot_longer(names_to = &quot;dataset&quot;, values_to = &quot;values&quot;, data_1:data_2) %&gt;% group_by(dataset) %&gt;% mutate(mean = mean(values)) %&gt;% ggplot(aes(values, fill = dataset))+ geom_dotplot(show.legend = FALSE)+ geom_vline(aes(xintercept = mean, color = dataset), size = 2, linetype = 2, show.legend = FALSE) wilcox.test(data_1, data_2) Wilcoxon rank sum exact test data: data_1 and data_2 W = 818, p-value = 2.419e-09 alternative hypothesis: true location shift is not equal to 0 9.5.4 Критерий χ², тест Фишера Если мы хотим сравнить распределение категориальных переменных, то обычно строят таблицы сопряженности и используют критерий χ². Например, из интервью с носителями одной деревни произвольным образом выбрали по пол часа и посчитали кол-во реализаций диалектных форм vs. недиалектных. В результате получилось что у женщин было 107 диалектных форм vs. 93 недиалектные, а у мужчин — 74 vs. 45. Значима ли зафиксированная разница? dialect_forms &lt;- read_csv(&quot;https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/dialect_forms_fake.csv&quot;) dialect_forms %&gt;% ggplot(aes(gender, fill = form))+ geom_bar() table(dialect_forms) gender form female male dialect 107 74 standard 93 45 prop.table(table(dialect_forms)) gender form female male dialect 0.3354232 0.2319749 standard 0.2915361 0.1410658 chisq.test(table(dialect_forms)) Pearson&#39;s Chi-squared test with Yates&#39; continuity correction data: table(dialect_forms) X-squared = 1.9525, df = 1, p-value = 0.1623 Критерий χ² считают относительно наблюдаемых \\(f_o\\) и ожидаемых \\(f_e\\) значений: \\[\\chi^2 = \\sum\\frac{\\left(f_0-f_e\\right)^2}{f_e}\\] Считается, что критерий χ² не стоит применять, если хотя бы одно из ожидаемых значений меньше 5. Давайте посмотрим на ожидаемые наблюдения: chisq.test(table(dialect_forms))$expected gender form female male dialect 113.47962 67.52038 standard 86.52038 51.47962 chisq.test(table(dialect_forms))$observed gender form female male dialect 107 74 standard 93 45 Если одно из ожидаемых значений меньше 5, то следует использовать тест Фишера: fisher.test(table(dialect_forms)) Fisher&#39;s Exact Test for Count Data data: table(dialect_forms) p-value = 0.1608 alternative hypothesis: true odds ratio is not equal to 1 95 percent confidence interval: 0.4279225 1.1396897 sample estimates: odds ratio 0.7004421 Вообще таблицы сопряженности бывают разные, да и тестов куда больше см. (Lydersen, Fagerland, and Laake 2009) 9.5.5 Критерий Мак Немара Во время диалектологической экспедиции от 20 информантов (10 мужчин, 10 женщин) были записаны списки слов. Получилось, что 13 информантов использовали в речи велярный фрикативный ɣ, а 22 — велярный стоп ɡ. Через 5 лет работали с теми же информантами и соотношение немного поменялось: 7 ɣ против 28 ɡ. Является ли получившаяся разница статистически значимой? repeated_dialect_forms &lt;- read_csv(&quot;https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/dialect_forms_repeated_fake.csv&quot;) table(repeated_dialect_forms) time feature after before fricative 7 13 stop 28 22 prop.table(table(repeated_dialect_forms)) time feature after before fricative 0.1000000 0.1857143 stop 0.4000000 0.3142857 repeated_dialect_forms %&gt;% ggplot(aes(time, fill = feature))+ geom_bar() mcnemar.test(table(repeated_dialect_forms)) McNemar&#39;s Chi-squared test with continuity correction data: table(repeated_dialect_forms) McNemar&#39;s chi-squared = 4.7805, df = 1, p-value = 0.02878 9.6 Послесловие P-value очень много ругают за то, что его очень часто понимают неправильно (Gigerenzer 2004), (Goodman 2008) за то, что само по себе p-value &lt; 0.05 слабый довод (Sterne and Smith 2001), (Nuzzo et al. 2014), (Wasserstein and Lazar 2016) Q: Why do so many colleges and grad schools teach p = 0.05? A: Because that’s still what the scientific community and journal editors use. Q: Why do so many people still use p = 0.05? A: Because that’s what they were taught in college or grad school (Wasserstein and Lazar 2016) В связи с этим, сейчас можно наблюдать большое обсуждение p-value vs. доверительные интервалы все нарастающую популярность Байесовской статистики 9.7 Рассказы Чехова и Зощенко 9.7.1 Рассказы Чехова и Зощенко собраны в tidy формате. Постройте график. Узнайте долю, которую составляют слова c леммой деньги от всех слов рассказа и проведите статистический тесты, сравнивающие [доли слов с леммой деньги] с знечением 0.000512 из частотного словаря русского языка [Шаров, Ляшевская 2011]. Приведите значение p-value для Чехова, округленное до 3 знаков после запятой: Приведите значение t-статистики для Чехова, округленное до 3 знаков после запятой: Приведите значение p-value для Зощенко, округленное до 3 знаков после запятой: Приведите значение t-статистики для Зощенко, округленное до 3 знаков после запятой: 9.7.2 Рассказы Чехова и Зощенко собраны в tidy формате. Постройте график. Проведите статистический тест, проверяющий, действительно ли Зощенко писал более короткие рассказы чем Чехов. Приведите значение p-value, округленное до 3 знаков после запятой Приведите абсолютное (т. е. неотрицательное) значение t-статистики, округленное до 3 знаков после запятой: 9.7.3 Посчитайте энтропию каждого рассказа, визуализируйте разницу между авторами и проведите статистический тест, который показывает, что энтропия в рассказах Зощенко выше. `summarise()` has grouped output by &#39;author&#39;, &#39;titles&#39;. You can override using the `.groups` argument. Приведите название рассказа с минимальной энтропией Надул Крест Вывеска Библиография Приведите название рассказа с максимальной энтропией Вор Великосветская История Черная магия Монастырь Приведите значение p-value, округленное до 3 знаков после запятой Приведите значение t-статистики, округленное до 3 знаков после запятой: 9.7.4 Визуализируйте количество слов и энтропию каждого автора. Какие выводы можно сделать на основании полученого графика? `summarise()` has grouped output by &#39;author&#39;, &#39;titles&#39;. You can override using the `.groups` argument. 9.8 Obamacare В 2010 Б. Обама подписал закон о доступном здравоохранении. В датасет записаны данные о доле незастрахованных людей (в процентах) в каждом штате в 2010 и в 2015 годах (исходные данные на kaggle). Нарисуйте график (я использовал geom_linerange(aes(ymin = …, ymax = …))) и проведите статистический тест, показывающий что произошло изменение. Приведите среднее значение разниц между годами Приведите значение p-value, округленное до 3 знаков после запятой Приведите значение t-статистики, округленное до 3 знаков после запятой: Ссылки на литературу "],["корреляция-и-регрессия.html", "10 Корреляция и регрессия 10.1 Дисперсия и стандартное отклонение 10.2 z-преобразование 10.3 Ковариация 10.4 Корреляция 10.5 Регрессионный анализ", " 10 Корреляция и регрессия 10.1 Дисперсия и стандартное отклонение Дисперсия — мера разброса значений наблюдений относительно среднего. \\[\\sigma^2_X = \\frac{\\sum_{i = 1}^n(x_i - \\bar{x})^2}{n - 1},\\] где \\(x_1, ..., x_n\\) — наблюдения; \\(\\bar{x}\\) — среднее всех наблюдений; \\(X\\) — вектор всех наблюдений; \\(n\\) — количество наблюдений. Представим, что у нас есть следующие данные: Тогда дисперсия — это сумма квадратов расстояний от каждой точки до среднего выборки (пунктирная линия) разделенное на количество наблюдений - 1 (по духу эта мера — обычное среднее, но если вас инетересует разница смещенной и несмещенной оценки дисперсии, см. видео). Для того чтобы было понятнее, что такое дисперсия, давайте рассмотрим несколько расспределений с одним и тем же средним, но разными дисперсиями: В R дисперсию можно посчитать при помощи функции var()3. set.seed(42) x &lt;- rnorm(20, mean = 50, sd = 10) var(x) [1] 172.2993 Проверим, что функция выдает то же, что мы записали в формуле. var(x) == sum((x - mean(x))^2)/(length(x)-1) [1] TRUE Так как дисперсия является квадратом отклонения, то часто вместо нее используют более интерпретируемое стандартное отклонение \\(\\sigma\\) — корень из дисперсии. В R ее можно посчитать при помощи функции sd(): sd(x) [1] 13.12628 sd(x) == sqrt(var(x)) [1] TRUE Посчитайте дисперсию переменной sleep_total в датасете msleep, встроенный в tidyverse. Ответ округлите до двух знаков после запятой. Посчитайте стандартное отклонение переменной sleep_total в датасете msleep, встроенный в tidyverse. Ответ округлите до двух знаков после запятой. 10.2 z-преобразование z-преобразование (еще используют термин нормализация) — это способ представления данных в виде расстояний от среднего, измеряемых в стандартных отклонениях. Для того чтобы его получить, нужно из каждого наблюдения вычесть среднее и результат разделить на стандартное отклонение. \\[x_i = \\frac{x_i - \\bar{x}}{\\sigma_X}\\] Если все наблюдения z-преобразовать, то получиться распределение с средним в 0 и стандартным отклонением 1 (или очень близко к ним). Само по себе \\(z\\)-преобразование ничего особенного нам про данные не говорит. Однако это преобразование позволяет привести к “общему знаменателю” разные переменные. Т. е. это преобразование ничего нам не говорит про конкретный набор данных, но позволяет сравнивать разные наборы данных. В R z-преобразование можно сделать при помощи функции scale(). Эта функция вовзращает матрицу, поэтому я использую индекс [,1], чтобы результат был вектором. set.seed(42) x &lt;- rnorm(20, mean = 50, sd = 10) scale(x)[,1] [1] 0.8982271 -0.5764146 0.1304317 0.3359234 0.1617734 -0.2270593 [7] 1.0053127 -0.2183246 1.3914857 -0.1939880 0.8478787 1.5958251 [13] -1.2042865 -0.3586002 -0.2477787 0.3382758 -0.3627629 -2.1699785 [19] -2.0054319 0.8594918 Проверим, что функция выдает то же, что мы записали в формуле. scale(x)[,1] == (x-mean(x))/sd(x) [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE [16] TRUE TRUE TRUE TRUE TRUE Однаждый я заполучил градусник со шкалой Фаренгейта и целый год измерял температуру в Москве при помощи градусников с шкалой Фарингейта и Цельсия. В датасет записаны средние значения для каждого месяца. Постройте график нормализованных и ненормализованных измерений. Что можно сказать про измерения, сделанные разными термометрами? 10.3 Ковариация Ковариация — эта мера ассоциации двух переменных. \\[cov(X, Y) = \\frac{\\sum_{i = 1}^n(x_i - \\bar{x})(y_i-\\bar{y})}{n - 1},\\] где \\((x_1, y_1), ..., (x_n, y_n)\\) — пары наблюдений; \\(\\bar{x}, \\bar{y}\\) — средние наблюдений; \\(X, Y\\) — векторы всех наблюдений; \\(n\\) — количество наблюдений. Представим, что у нас есть следующие данные: Тогда, согласно формуле, для каждой точки вычисляется следующая площадь (пуктирными линиями обозначены средние): Если значения \\(x_i\\) и \\(y_i\\) какой-то точки либо оба больше, либо оба меньше средних \\(\\bar{x}\\) и \\(\\bar{y}\\), то получившееся произведение будет иметь знак +, если же наоборот — знак -. На графике это показано цветом. Таким образом, если много красных прямоугольников, то значение суммы будет положительное и обозначать положительную связь (чем больше \\(x\\), тем больше \\(y\\)), а если будет много синий прямоугольников, то значение суммы отрицательное и обозначать положительную связь (чем больше \\(x\\), тем меньше \\(y\\)). Непосредственно значение ковариации не очень информативно, так как может достаточно сильно варьироваться от датасета к датасету. В R ковариацию можно посчитать при помощи функции cov(). set.seed(42) x &lt;- rnorm(10, mean = 50, sd = 10) y &lt;- x + rnorm(10, sd = 10) cov(x, y) [1] 18.72204 cov(x, -y*2) [1] -37.44407 Как видно, простое умножение на два удвоило значение ковариации, что показывает, что непосредственно ковариацию использовать для сравнения разных датасетов не стоит. Проверим, что функция выдает то же, что мы записали в формуле. cov(x, y) == sum((x-mean(x))*(y - mean(y)))/(length(x)-1) [1] TRUE 10.4 Корреляция Корреляция — это мера ассоциации/связи двух числовых переменных. Помните, что бытовое применение этого термина к категориальным переменным (например, корреляция цвета глаз и успеваемость на занятиях по R) не имеет смысла с точки зрения статистики. 10.4.1 Корреляция Пирсона Коэффициент корреляции Пирсона — базовый коэффициент ассоциации переменных, однако стоит помнить, что он дает неправильную оценку, если связь между переменными нелинейна. \\[\\rho_{X,Y} = \\frac{cov(X, Y)}{\\sigma_X\\times\\sigma_Y} = \\frac{1}{n-1}\\times\\sum_{i = 1}^n\\left(\\frac{x_i-\\bar{x}}{\\sigma_X}\\times\\frac{y_i-\\bar{y}}{\\sigma_Y}\\right),\\] где \\((x_1, y_1), ..., (x_n, y_n)\\) — пары наблюдений; \\(\\bar{x}, \\bar{y}\\) — средние наблюдений; \\(X, Y\\) — векторы всех наблюдений; \\(n\\) — количество наблюдений. Последнее уравнение показывает, что коэффициент корреляции Пирсона можно представить как среднее (с поправкой, поэтому \\(n-1\\), а не \\(n\\)) произведение \\(z\\)-нормализованных значений двух переменных. Эта нормализация приводит к тому, что значения корреляции имеют те же свойства знака коэффициента что и ковариация: если коэффициент положительный (т. е. много красных прямоугольников) — связь между переменными положительная (чем больше \\(x\\), тем больше \\(y\\)), если коэффициент отрицательный (т. е. много синих прямоугольников) — связь между переменными отрицательная (чем больше \\(x\\), тем меньше \\(y\\)); значение корреляции имееет независимое от типа данных интеретация: если модуль коэффициента близок к 1 или ему равен — связь между переменными сильная, если модуль коэффициента близок к 0 или ему равен — связь между переменными слабая. Для того чтобы было понятнее, что такое корреляция, давайте рассмотрим несколько расспределений с разными значениями корреляции: Как видно из этого графика, чем ближе модуль корреляции к 1, тем боллее компактно расположены точки друг к другу, чем ближе к 0, тем более рассеяны значения. Достаточно легко научиться приблизительно оценивать коэфициент корреляции на глаз, поиграв 2–5 минут в игру “Угадай корреляцию” здесь или здесь. В R коэффициент корреляции Пирсона можно посчитать при помощи функции cor(). set.seed(42) x &lt;- rnorm(15, mean = 50, sd = 10) y &lt;- x + rnorm(15, sd = 10) cor(x, y) [1] 0.6659041 Проверим, что функция выдает то же, что мы записали в формуле. cor(x, y) == cov(x, y)/(sd(x)*sd(y)) [1] TRUE cor(x, y) == sum(scale(x)*scale(y))/(length(x)-1) [1] TRUE Посчитайте на основе датасета с температурой корреляцию между разными измерениями в шкалах Фарингейта и Цельсия? Результаты округлите до трех знаков после запятой. 10.4.2 Ранговые корреляции Спирмана и Кендалла Коэффициент корреляции Пирсона к сожалению, чувствителен к значениям наблюдений. Если связь между переменными нелинейна, то оценка будет получаться смещенной. Рассмотрим, например, словарь [Ляшевской, Шарова 2011]: freqdict &lt;- read_tsv(&quot;https://github.com/agricolamz/DS_for_DH/raw/master/data/freq_dict_2011.csv&quot;) freqdict %&gt;% arrange(desc(freq_ipm)) %&gt;% mutate(id = 1:n()) %&gt;% slice(1:100) -&gt; filered_freqdict filered_freqdict %&gt;% ggplot(aes(id, freq_ipm, label = lemma))+ geom_point()+ ggrepel::geom_text_repel()+ scale_y_log10() В целом корреляция между рангом и частотой должна быть высокая, однако связь между этими переменными нелинейна, так что коэффициент корреляции Пирсона не такой уж и высокий: cor(filered_freqdict$freq_ipm, filered_freqdict$id) [1] -0.6307876 Для решения той проблемы обычно используют ранговые коэффециенты коррляции Спирмана и Кендала, которые принимают во внимание ранг значения, а не его непосредственное значение. cor(filered_freqdict$freq_ipm, filered_freqdict$id, method = &quot;spearman&quot;) [1] -1 cor(filered_freqdict$freq_ipm, filered_freqdict$id, method = &quot;kendall&quot;) [1] -1 Давайте сравним с предыдущими наблюдениями и их логаотфмамиы: cor(x, y) == cor(log(x), log(y)) [1] FALSE cor(x, y, method = &quot;spearman&quot;) == cor(log(x), log(y), method = &quot;spearman&quot;) [1] TRUE cor(x, y, method = &quot;kendall&quot;) == cor(log(x), log(y), method = &quot;kendall&quot;) [1] TRUE 10.5 Регрессионный анализ 10.5.1 Основы Суть регрессионного анализа в моделировании связи между двумя и более переменными при помощи прямой на плоскости. Формула прямой зависит от двух параметров: свободного члена (intercept) и углового коэффициента (slope). Укажите значение свободного члена для красной прямой. -2 -1 0 1 2 3 4 Укажите значение свободного члена для зеленой прямой. -2 -1 0 1 2 3 4 Укажите значение свободного члена для синей прямой. -2 -1 0 1 2 3 4 Укажите значение углового коэффициента для красной прямой. -2 -1 0 1 2 3 4 Укажите значение углового коэффициента для зеленой прямой. -2 -1 0 1 2 3 4 Укажите значение углового коэффициента для синей прямой. -2 -1 0 1 2 3 4 Когда мы пытаемся научиться предсказывать данные одной переменной \\(Y\\) при помощи другой переменной \\(X\\), мы получаем похожую формулу: \\[y_i = \\hat\\beta_0 + \\hat\\beta_1 \\times x_i + \\epsilon_i,\\] где \\(x_i\\) — \\(i\\)-ый элемент вектора значений \\(X\\); \\(y_i\\) — \\(i\\)-ый элемент вектора значений \\(Y\\); \\(\\hat\\beta_0\\) — оценка случайного члена (intercept); \\(\\hat\\beta_1\\) — оценка углового коэффициента (slope); \\(\\epsilon_i\\) — \\(i\\)-ый остаток, разница между оценкой модели (\\(\\hat\\beta_0 + \\hat\\beta_1 \\times x_i\\)) и реальным значением \\(y_i\\); весь вектор остатков иногда называют случайным шумом (на графике выделены красным). Задача регрессии — оценить параметры \\(\\hat\\beta_0\\) и \\(\\hat\\beta_1\\), если нам известны все значения \\(x_i\\) и \\(y_i\\) и мы пытаемся минимизировать значния \\(\\epsilon_i\\). В данном конкретном случае, задачу можно решить аналитически и получить следующие формулы: \\[\\hat\\beta_1 = \\frac{(\\sum_{i=1}^n x_i\\times y_i)-n\\times\\bar x \\times \\bar y}{\\sum_{i = 1}^n(x_i-\\bar x)^2}\\] \\[\\hat\\beta_0 = \\bar y - \\hat\\beta_1\\times\\bar x\\] 10.5.2 Первая регрессия Давайте попробуем смоделировать количество слов и в рассказах М. Зощенко в зависимости от длины рассказа: zo &lt;- read_tsv(&quot;https://github.com/agricolamz/DS_for_DH/raw/master/data/tidy_zoshenko.csv&quot;) zo %&gt;% filter(word == &quot;и&quot;) %&gt;% distinct() %&gt;% ggplot(aes(n_words, n))+ geom_point()+ labs(x = &quot;количество слов в рассказе&quot;, y = &quot;количество и&quot;) Мы видим, несколько одиночных точек, давайте избавимся от них и добавим регрессионную линию при помощи функции geom_smooth(): zo %&gt;% filter(word == &quot;и&quot;, n_words &lt; 1500) %&gt;% distinct() -&gt; zo_filtered zo_filtered %&gt;% ggplot(aes(n_words, n))+ geom_point()+ geom_smooth(method = &quot;lm&quot;, se = FALSE)+ labs(x = &quot;количество слов в рассказе&quot;, y = &quot;количество и&quot;) Чтобы получить формулу этой линии нужно запустить функцию, которая оценивает линейную регрессию: fit &lt;- lm(n~n_words, data = zo_filtered) fit Call: lm(formula = n ~ n_words, data = zo_filtered) Coefficients: (Intercept) n_words -1.47184 0.04405 Вот мы и получили коэффициенты, теперь мы видим, что наша модель считает следующее: \\[n = -1.47184 + 0.04405 \\times n\\_words\\] Более подробную информцию можно посмотреть, если запустить модель в функцию summary(): summary(fit) Call: lm(formula = n ~ n_words, data = zo_filtered) Residuals: Min 1Q Median 3Q Max -19.6830 -4.3835 0.8986 4.6486 19.6413 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -1.471840 2.467149 -0.597 0.553 n_words 0.044049 0.003666 12.015 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 7.945 on 64 degrees of freedom Multiple R-squared: 0.6928, Adjusted R-squared: 0.688 F-statistic: 144.4 on 1 and 64 DF, p-value: &lt; 2.2e-16 В разделе Coefficients содержится информацию про наши коэффициенты: Estimate – полученная оценка коэффициентов; Std. Error – стандартная ошибка среднего; t value – \\(t\\)-статистика, полученная при проведении одновыборочного \\(t\\)-теста, сравнивающего данный коэфициент с 0; Pr(&gt;|t|) – полученное \\(p\\)-значение; Multiple R-squared и Adjusted R-squared — одна из оценок модели, показывает связь между переменными. Без поправок совпадает с квадратом коэффициента корреляции Пирсона: cor(zo_filtered$n_words, zo_filtered$n)^2 [1] 0.6928376 F-statistic — \\(F\\)-статистика полученная при проведении теста, проверяющего, не являются ли хотя бы один из коэффицинтов статистически значимо отличается от нуля. Совпадает с результатами дисперсионного анализа (ANOVA). Теперь мы можем даже предсказывать значения, которые мы еще не видели. Например, сколько будет и в рассказе Зощенко длиной 1000 слов? predict(fit, tibble(n_words = 1000)) 1 42.57715 Постройте ленейную ргерессию на основании рассказов А. Чехова, предсказывая количество и на основании количства слов. При моделировании используйте только рассказы длиной меньше 2500 слов. Укажите свободный член получившейся модели, округлив его до 3 знаков после запятой. Укажите угловой коффициент получившейся модели, округлив его до 3 знаков после запятой. Укажите предсказания модели для рассказа длиной 1000 слов, округлив получнное значение до 3 знаков после запятой. 10.5.3 Категориальные переменные Что если мы хотим включить в наш анализ категориальные переменные? Давайте рассмотрим простой пример с рассказами Чехова и Зощенко, которые мы рассматривали в прошлом разделе. Мы будем анализировать логарифм доли слов деньги: chekhov &lt;- read_tsv(&quot;https://github.com/agricolamz/DS_for_DH/raw/master/data/tidy_chekhov.tsv&quot;) zoshenko &lt;- read_tsv(&quot;https://github.com/agricolamz/DS_for_DH/raw/master/data/tidy_zoshenko.csv&quot;) chekhov$author &lt;- &quot;Чехов&quot; zoshenko$author &lt;- &quot;Зощенко&quot; chekhov %&gt;% bind_rows(zoshenko) %&gt;% filter(str_detect(word, &quot;деньг&quot;)) %&gt;% group_by(author, titles, n_words) %&gt;% summarise(n = sum(n)) %&gt;% mutate(log_ratio = log(n/n_words)) -&gt; checkov_zoshenko Визуализация выглядит так: Красной точкой обозначены средние значения, так что мы видим, что между двумя писателями есть разница, но является ли она статистически значимой? В прошлом разделе, мы рассмотрели, что в таком случае можно сделать t-test: t.test(log_ratio~author, data = checkov_zoshenko, var.equal =TRUE) # здесь я мухлюю, отключая поправку Уэлча Two Sample t-test data: log_ratio by author t = 5.6871, df = 125, p-value = 8.665e-08 alternative hypothesis: true difference in means between group Зощенко and group Чехов is not equal to 0 95 percent confidence interval: 0.8606107 1.7793181 sample estimates: mean in group Зощенко mean in group Чехов -5.021262 -6.341226 Разница между группами является статистически значимой (t(125) = 5.6871, p-value = 8.665e-08). Для того, чтобы запустить регрессию на категориальных данных категориальная переменная автоматически разбивается на группу бинарных dummy-переменных: tibble(author = c(&quot;Чехов&quot;, &quot;Зощенко&quot;), dummy_chekhov = c(1, 0), dummy_zoshenko = c(0, 1)) Дальше для регрессионного анализа выкидывают одну из переменных, так как иначе модель не сойдется (dummy-переменных всегда n-1, где n — количество категорий в переменной). tibble(author = c(&quot;Чехов&quot;, &quot;Зощенко&quot;), dummy_chekhov = c(1, 0)) Если переменная dummy_chekhov принимает значение 1, значит речь о рассказе Чехова, а если принимает значение 0, то о рассказе Зощенко. Если вставить нашу переменную в регрессионную формулу получится следующее: \\[y_i = \\hat\\beta_0 + \\hat\\beta_1 \\times \\text{dummy_chekhov} + \\epsilon_i,\\] Так как dummy_chekhov принимает либо значение 1, либо значение 0, то получается, что модель предсказывает лишь два значения: \\[y_i = \\left\\{\\begin{array}{ll}\\hat\\beta_0 + \\hat\\beta_1 \\times 1 + \\epsilon_i = \\hat\\beta_0 + \\hat\\beta_1 + \\epsilon_i\\text{, если рассказ Чехова}\\\\ \\hat\\beta_0 + \\hat\\beta_1 \\times 0 + \\epsilon_i = \\hat\\beta_0 + \\epsilon_i\\text{, если рассказ Зощенко} \\end{array}\\right.\\] Таким образом, получается, что свободный член \\(\\beta_0\\) и угловой коэффициент \\(\\beta_1\\) в регресси с категориальной переменной получает другую интерпретацию. Одно из значений переменной кодируется при помощи \\(\\beta_0\\), а сумма коэффициентов \\(\\beta_0+\\beta_1\\) дают другое значение переменной. Так что \\(\\beta_1\\) — это разница между оценками двух значений переменной. Давайте теперь запустим регрессию на этих же данных: fit2 &lt;- lm(log_ratio~author, data = checkov_zoshenko) summary(fit2) Call: lm(formula = log_ratio ~ author, data = checkov_zoshenko) Residuals: Min 1Q Median 3Q Max -2.8652 -0.6105 -0.0607 0.6546 3.2398 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -5.0213 0.2120 -23.680 &lt; 2e-16 *** authorЧехов -1.3200 0.2321 -5.687 8.67e-08 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.9717 on 125 degrees of freedom Multiple R-squared: 0.2056, Adjusted R-squared: 0.1992 F-statistic: 32.34 on 1 and 125 DF, p-value: 8.665e-08 Во-первых стоит обратить внимание на то, что R сам преобразовал нашу категориальную переменную в dummy-переменную authorЧехов. Во-вторых, можно заметить, что значения t-статистики и p-value совпадают с результатами полученными нами в t-тесте выше. Статистическти значимый коэффициент при аргументе authorЧехов следует интерпретировать как разницу средних между логарифмом долей в рассказах Чехова и Зощенко. В работе (Coretta 2017, https://goo.gl/NrfgJm) рассматривается отношения между длительностью гласного и придыхание согласного. Автор собрал данные 5 носителей исландского. Дальше он извлек длительность гласного, после которого были придыхательные и непридыхательные. Скачайте данные и постройте регрессионную модель, предсказывающую длительность гласного на основе . 10.5.4 Множественная регрессия Множественная регрессия позволяет проанализировать связь между зависимой и несколькими зависимыми переменными. Формула множественной регрессии не сильно отличается от формулы обычной линейной регрессии: \\[y_i = \\hat\\beta_0 + \\hat\\beta_1 \\times x_{1i}+ \\dots+ \\hat\\beta_n \\times x_{ni} + \\epsilon_i,\\] \\(x_{ki}\\) — \\(i\\)-ый элемент векторов значений \\(X_1, \\dots, X_n\\); \\(y_i\\) — \\(i\\)-ый элемент вектора значений \\(Y\\); \\(\\hat\\beta_0\\) — оценка случайного члена (intercept); \\(\\hat\\beta_k\\) — коэфциент при переменной \\(X_{k}\\); \\(\\epsilon_i\\) — \\(i\\)-ый остаток, разница между оценкой модели (\\(\\hat\\beta_0 + \\hat\\beta_1 \\times x_i\\)) и реальным значением \\(y_i\\); весь вектор остатков иногда называют случайным шумом. В такой регресии предикторы могут быть как числовыми, так и категориальными (со всеми вытекающими последствиями, которые мы обсудили в предудщем разделе). Такую регрессию чаще всего сложно визуализировать, так как в одну регрессионную линию вкладываются сразу несколько переменных. Попробуем предсказать длину лепестка на основе длины чашелистик и вида ириса: iris %&gt;% ggplot(aes(Sepal.Length, Petal.Length, color = Species))+ geom_point() Запустим регрессию: fit3 &lt;- lm(Petal.Length ~ Sepal.Length+ Species, data = iris) summary(fit3) Call: lm(formula = Petal.Length ~ Sepal.Length + Species, data = iris) Residuals: Min 1Q Median 3Q Max -0.76390 -0.17875 0.00716 0.17461 0.79954 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -1.70234 0.23013 -7.397 1.01e-11 *** Sepal.Length 0.63211 0.04527 13.962 &lt; 2e-16 *** Speciesversicolor 2.21014 0.07047 31.362 &lt; 2e-16 *** Speciesvirginica 3.09000 0.09123 33.870 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.2826 on 146 degrees of freedom Multiple R-squared: 0.9749, Adjusted R-squared: 0.9744 F-statistic: 1890 on 3 and 146 DF, p-value: &lt; 2.2e-16 Все предикторы статистически значимы. Давайте посмотрим предсказания модели для всех наблюдений: iris %&gt;% mutate(prediction = predict(fit3)) %&gt;% ggplot(aes(Sepal.Length, prediction, color = Species))+ geom_point() Всегда имеет смысл визуализировать, что нам говорит наша модель. Если использовать пакет ggeffects (или предшествовавший ему пакет effects), это можно сделать не сильно задумываясь, как это делать: library(ggeffects) plot(ggpredict(fit3, terms = c(&quot;Sepal.Length&quot;, &quot;Species&quot;))) Как видно из графиков, наша модель имеет одинаковые угловые коэффициенты (slope) для каждого из видов ириса и разные свободные члены (intercept). summary(fit3) Call: lm(formula = Petal.Length ~ Sepal.Length + Species, data = iris) Residuals: Min 1Q Median 3Q Max -0.76390 -0.17875 0.00716 0.17461 0.79954 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -1.70234 0.23013 -7.397 1.01e-11 *** Sepal.Length 0.63211 0.04527 13.962 &lt; 2e-16 *** Speciesversicolor 2.21014 0.07047 31.362 &lt; 2e-16 *** Speciesvirginica 3.09000 0.09123 33.870 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.2826 on 146 degrees of freedom Multiple R-squared: 0.9749, Adjusted R-squared: 0.9744 F-statistic: 1890 on 3 and 146 DF, p-value: &lt; 2.2e-16 \\[y_i = \\left\\{\\begin{array}{ll} -1.70234 + 0.63211 \\times \\text{Sepal.Length} + \\epsilon_i\\text{, если вид setosa}\\\\ -1.70234 + 2.2101 + 0.63211 \\times \\text{Sepal.Length} + \\epsilon_i\\text{, если вид versicolor} \\\\ -1.70234 + 3.09 + 0.63211 \\times \\text{Sepal.Length} + \\epsilon_i\\text{, если вид virginica} \\end{array}\\right.\\] 10.5.5 Сравнение моделей Как нам решить, какая модель лучше? Ведь теперь можно добавить сколько угодно предикторов? Давайте создадим новую модель без предиктора Species: fit4 &lt;- lm(Petal.Length ~ Sepal.Length, data = iris) можно сравнивать статистическую значимость предикторов можно сравнивать \\(R^2\\) summary(fit3)$adj.r.squared [1] 0.9743786 summary(fit4)$adj.r.squared [1] 0.7583327 чаще всего используют так называемые информационные критерии, самый популярный – AIC (Akaike information criterion). Сами по себе значение этого критерия не имеет значения – только в сравнении моделей, построенных на похожих данных. Чем меньше значение, тем модель лучше. AIC(fit3, fit4) 10.5.6 Послесловие сущетсвуют ограничения на применение линейной регресии связь между предсказываемой переменной и предикторами должна быть линейной остатки должны быть нормально распределены (оценивайте визуально) дисперсия остатков вокруг регрессионной линии должно быть постоянно (гомоскидастично) предикторы не должны коррелировать друг с другом все наблюдения в регрессии должны быть независимы друг от друга Вот так вот выглядят остатки нашей модели на основе датасета iris. Смотрите пост, в котором обсуждается, как интерпретировать график остатков. plot(fit3, which=c(1, 2)) сущетсвуют трюки, позволяющие автоматически отбирать модели (см. функцию step()) существует достаточно большое семейство регрессий, который зависят от типа независимой (предсказываемой) переменной или ее распределения логистическая (если предсказываемая переменная имеет два возможных исхода) мультиномиальная (если предсказываемая переменная имеет больше двух возможных дискретных исхода) нелиненые регресии (если связь между переменными нелинейна) регрессия со смешанными эффектами (если внутри данных есть группировки, т. е. наблюдения не независимы) и другие. Как и в других функциях, вычисляющих описательную статистику (mean(), median(), max(), min() и др.), функция var() (и все остальные функции, которые мы будем обсуждать sd(), cov()) возвращают NA, если в векторе есть пропущенные значения. Чтобы изменить это поведение, нужно добавить аргумент na.rm = TRUE.↩︎ "],["работа-статистического-детектива.html", "11 Работа статистического детектива 11.1 Введение 11.2 Возможно ли такое среднее? 11.3 Пакет statcheck 11.4 Пакет digitize", " 11 Работа статистического детектива library(&quot;tidyverse&quot;) 11.1 Введение До сих пор мы лишь использовали разные статистические тесты, чтобы ответить на разные исследовательские вопросы, которые могут возникнуть. Однако часто в статистические выкладки никто не вчитывается и принимает их как данность, надеясь что софт все правильно посчитал. Здесь есть две опасности: во-первых, бывают недобросовестные исследователи; во-вторых, люди часто ошибаются во время применения и представления результатов статистического анализа (и видимо, это случается чаще). Мы рассмотрим несколько методов, которые позволят проверять некоторые простые случаи, что может быть полезно при критическом чтении (например, во время ревью статей ученых и дата журналистов) в случаях, когда к данным нет доступа. Данный раздел вдохнавлен лекцией Кристин Сайнани. 11.2 Возможно ли такое среднее? Представим себе, что кто-то провел эксперимент с биномиальными данными, например, посчитал количество не в рассказе А. П. Чехова длинной 322 слова “Жизнь прекрасна!” и обнаружил среднее 0.095. Возможно ли это? Давайте посмотри на все возможные результаты: tibble(ratio = round(1:322/322, 3)) %&gt;% ggplot()+ geom_vline(aes(xintercept = ratio), color = &quot;lightblue&quot;)+ geom_vline(xintercept = 0.095, color = &quot;red&quot;) Так ничего не видно, давайте сконцентрируемся на промежуке от 0.085 до 0.1, в котором лежит завяленное значение 0.095, и добавим подписи: tibble(ratio = round(1:322/322, 3)) %&gt;% ggplot()+ geom_vline(aes(xintercept = ratio), color = &quot;lightblue&quot;)+ geom_vline(xintercept = 0.095, color = &quot;red&quot;)+ geom_label(aes(x = ratio, label = ratio), y = 0.5)+ xlim(0.085, 0.1) Мы видим, что красные линии повторяются регулярно с интервалом 0.03 и что синяя линия явно не вписывается в этот паттерн. Может быть было использовано другое округление? tibble(ratio = round(1:322/322, 5)) %&gt;% ggplot()+ geom_vline(aes(xintercept = ratio), color = &quot;lightblue&quot;)+ geom_vline(xintercept = 0.095, color = &quot;red&quot;)+ geom_label(aes(x = ratio, label = ratio), y = 0.5)+ xlim(0.085, 0.1) Если бы числа округлялись вверх, на месте 0.09317 мы бы увидели 0.094. Если бы числа округлялись вниз, на месте 0.09627 мы бы увидели 0.096. Так что доля не в рассказе длинной 322 никак не может быть 0.095. Может быть автор ошибся с количеством слов? 200:400*0.095 [1] 19.000 19.095 19.190 19.285 19.380 19.475 19.570 19.665 19.760 19.855 [11] 19.950 20.045 20.140 20.235 20.330 20.425 20.520 20.615 20.710 20.805 [21] 20.900 20.995 21.090 21.185 21.280 21.375 21.470 21.565 21.660 21.755 [31] 21.850 21.945 22.040 22.135 22.230 22.325 22.420 22.515 22.610 22.705 [41] 22.800 22.895 22.990 23.085 23.180 23.275 23.370 23.465 23.560 23.655 [51] 23.750 23.845 23.940 24.035 24.130 24.225 24.320 24.415 24.510 24.605 [61] 24.700 24.795 24.890 24.985 25.080 25.175 25.270 25.365 25.460 25.555 [71] 25.650 25.745 25.840 25.935 26.030 26.125 26.220 26.315 26.410 26.505 [81] 26.600 26.695 26.790 26.885 26.980 27.075 27.170 27.265 27.360 27.455 [91] 27.550 27.645 27.740 27.835 27.930 28.025 28.120 28.215 28.310 28.405 [101] 28.500 28.595 28.690 28.785 28.880 28.975 29.070 29.165 29.260 29.355 [111] 29.450 29.545 29.640 29.735 29.830 29.925 30.020 30.115 30.210 30.305 [121] 30.400 30.495 30.590 30.685 30.780 30.875 30.970 31.065 31.160 31.255 [131] 31.350 31.445 31.540 31.635 31.730 31.825 31.920 32.015 32.110 32.205 [141] 32.300 32.395 32.490 32.585 32.680 32.775 32.870 32.965 33.060 33.155 [151] 33.250 33.345 33.440 33.535 33.630 33.725 33.820 33.915 34.010 34.105 [161] 34.200 34.295 34.390 34.485 34.580 34.675 34.770 34.865 34.960 35.055 [171] 35.150 35.245 35.340 35.435 35.530 35.625 35.720 35.815 35.910 36.005 [181] 36.100 36.195 36.290 36.385 36.480 36.575 36.670 36.765 36.860 36.955 [191] 37.050 37.145 37.240 37.335 37.430 37.525 37.620 37.715 37.810 37.905 [201] 38.000 Среди полученных числе целые числа есть только в значениях 200 и 400. Так что, если автор и ошибся в количестве слов, то слишком масштабно. Еще автор мог ошибиться и там, и там. Этот процесс можно немного автоматизировать: round(200:400*0.095) == 200:400*0.095 [1] TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [97] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [109] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [121] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [133] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [145] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [157] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [169] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [181] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [193] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE Эта идея лежит в основе Granularity-Related Inconsistent Means test (GRIM). Я не нашел его реализации на R, но вот есть он-лайн приложение. 11.3 Пакет statcheck Пакет statcheck написан для извлечения и проверки результатов статистических тестов, которые приводятся в статьях. Рассмотрим пример двустороннего и одностороннего t-тестов: t.test(data = mtcars, qsec ~ am) Welch Two Sample t-test data: qsec by am t = 1.2878, df = 25.534, p-value = 0.2093 alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0 95 percent confidence interval: -0.4918522 2.1381679 sample estimates: mean in group 0 mean in group 1 18.18316 17.36000 t.test(data = mtcars, qsec ~ am, alternative = &quot;greater&quot;) Welch Two Sample t-test data: qsec by am t = 1.2878, df = 25.534, p-value = 0.1047 alternative hypothesis: true difference in means between group 0 and group 1 is greater than 0 95 percent confidence interval: -0.2677649 Inf sample estimates: mean in group 0 mean in group 1 18.18316 17.36000 Запустим в функцию statcheck() три варианта: результат двустороннего теста; результат одностороннего теста; совсем неправильный результат. library(&quot;statcheck&quot;) s &lt;- statcheck(c(&quot;t(25.534) = 1.2878, p = 0.21&quot;, &quot;t(25.534) = 1.2878, p = 0.10&quot;, &quot;t(22.716) = 3.7671, p &lt; 0.01&quot;)) | | | 0% | |======================= | 33% | |=============================================== | 67% | |======================================================================| 100% s Теперь в переменной s находится датафрейм со следующими переменными: Source Statistic df1 df2 Test.Comparison Value Reported.Comparison Reported.P.Value Computed Raw Error DecisionError OneTail OneTailedInTxt APAfactor Функция statcheck() работает со следующими статистиками: \\(t\\)-статистика, \\(F\\)-статистика (мы ее видели в регрессии), коэффициент корреляции, хи-квадрат и \\(z\\)-score (используется в z-тесте). В мануале к пакету описаны много дополнительных функций, которые позволяют не копировать текст из статьи, а автоматически извлекать данные для проверки из .pdf или .html. 11.4 Пакет digitize Иногда нам может случится, что данные представлены визуально: set.seed(42) tibble(x = rnorm(20, mean = 40, sd = 10), y = x + rnorm(20, mean = 0, sd = 5)) %&gt;% ggplot(aes(x, y))+ geom_point()+ annotate(geom = &quot;text&quot;, x = 20, y = 60, label = &quot;r = 0.92&quot;, size = 8) Как бы нам проверить корреляцию Пирсона, которая представлена на графике? Для этого мы воспользуемся пакетом digitize (однако аналогичные операции можно сделать и онлайн). На первом шаге нужно определить границы. При помощи функции ReadAndCal() сначала отметьте минимальное значение по оси x, затем максимальное значение по оси х, затем отметьте минимальное значение по оси y, затем максимальное значение по оси y: library(digitize) calibration &lt;- ReadAndCal(&#39;images/test_correlaton.png&#39;) После того, как вы отметите границы появятся синие крестики: Следующий шаг — это отметить наблюдения. Это делается при помощи функции DigitData() (нажмите на кнопку Finish наверху или клавишу Esc): data.points &lt;- DigitData(col = &#39;red&#39;) Теперь на графике появились не только синие крестики, но и красные точки: После этого используйте функцию Calibrate(), чтобы откалибрировать полученные точки: df &lt;- Calibrate(data.points, calibration, 15, # минимум по оси x 60, # максимум по оси x 20, # минимум по оси y 60) # максимум по оси y Давайте проверим, как точки соотносятся с оригиналом: df$type &lt;- &quot;obtained&quot; set.seed(42) tibble(x = rnorm(20, mean = 40, sd = 10), y = x + rnorm(20, mean = 0, sd = 5), type = &quot;original&quot;) %&gt;% bind_rows(df) %&gt;% ggplot(aes(x, y, color = type))+ geom_point() Результат достаточно близкий, давайте теперь проверим коэффициент корреляции: cor(df$x, df$y) [1] 0.9522989 И вот мы выяснили, что коэффициент корреляции Пирсона на этих данных равен 0.95, что отличается от заявленных 0.92. У этого метода, конечно, есть очевидные недостатки: при большом количестве точек метод становится слишком трудоемким; сам процесс тыкания плохо верефицируем, исследователь может случайно ткнуть два раза на одну точку или отметить два раза группу точек, потому что ему показалось, что раньше он эту группу не отмечал; даже при маленьком количестве точек мы не можем заметить случаи, когда значения совпадают или слишком похожи. Т. е. в оригинальных данных может быть две точки, а детектив поставит лишь одну; если Ваше изображение повернуто, то результаты может получиться неправильный. "],["ссылки-на-литературу.html", "Ссылки на литературу", " Ссылки на литературу "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
